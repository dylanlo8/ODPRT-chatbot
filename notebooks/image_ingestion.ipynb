{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/odprt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from chatbot.backend.services.vector_db.db import VectorDB\n",
    "from chatbot.backend.services.models.models import vlm\n",
    "from chatbot.backend.services.models.embedding_model import embedding_model\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\"archi.png\", \"34.png\"] #\"34.png\", \"43.png\", \"46.png\", \"160.png\", \n",
    "image_paths = [f\"chatbot/backend/sample_images/{path}\" for path in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing vlm\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing vlm\")\n",
    "image_summaries = vlm.generate_image_summaries(useful_image_paths=image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing embedding model\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing embedding model\")\n",
    "description_embeddings = embedding_model.batch_encode(image_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"doc_id\": image_paths[i],\n",
    "        \"doc_source\": \"sample_images\",\n",
    "        \"text\": \"\",\n",
    "        \"text_dense_embedding\": [0 for _ in range(1024)],  # Placeholder for text dense embedding\n",
    "        \"text_sparse_embedding\": [],  # Empty sparse vector\n",
    "        \"description\": image_summaries[i],\n",
    "        \"description_embedding\": description_embeddings[i],  # Embedding for Image Descriptions\n",
    "    }\n",
    "    for i in range(len(image_paths))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'data' : data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingested successfully\n"
     ]
    }
   ],
   "source": [
    "url = \"http://0.0.0.0:8000/vector-db/insert-documents/\"\n",
    "\n",
    "# Make the POST request to ingest the data\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Data ingested successfully\")\n",
    "else:\n",
    "    print(f\"Failed to ingest data: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://0.0.0.0:8000/vector-db/image-search/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"query\" : \"Model Architecture\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingested successfully\n",
      "{'context': 'Doc_id: chatbot/backend/sample_images/archi.png \\n Description: The image outlines the architecture of a RAG (Retrieval-Augmented Generation) system. The RAG Workflow involves users interacting with a chatbot that queries a Milvus Vector Database for relevant information. The database ingests various document types (FAQs, emails, PPTX, PDFs, and Excel files) and retrieves top K similar chunks for the query. The chatbot stores user chat history in a Firebase Relational Database. The Deployment and Scaling section shows users interacting with a load balancer that routes queries to RAG servers. Analytics & Dashboard tracks user queries, common topics, and unanswered queries for human analysis and refinement. The legend categorizes the architecture components into generative steps, functions/APIs, databases, and servers.\\n\\nDoc_id: chatbot/backend/sample_images/archi.png \\n Description: The image outlines the architecture of a RAG (Retrieval-Augmented Generation) system. The RAG Workflow involves users interacting with a chatbot that queries a Milvus Vector Database for relevant information. The database ingests various document types (FAQs, emails, PPTX, PDFs, and Excel files) and retrieves top K similar chunks for the query. The chatbot stores user chat history in a Firebase Relational Database. The Deployment and Scaling section shows users interacting with a load balancer that routes queries to RAG servers. Analytics & Dashboard tracks user queries, common topics, and unanswered queries for human analysis and refinement. The legend categorizes the architecture components into generative steps, functions/APIs, databases, and servers.\\n\\nDoc_id: chatbot/backend/sample_images/archi.png \\n Description: The image outlines the architecture of a RAG (Retrieval-Augmented Generation) system. The RAG Workflow involves users interacting with a chatbot that queries a Milvus Vector Database for relevant information. The database ingests various document types (FAQs, emails, PPTX, PDFs, and Excel files) and retrieves top K similar chunks for the query. The chatbot stores user chat history in a Firebase Relational Database. The Deployment and Scaling section shows users interacting with a load balancer that routes queries to RAG servers. Analytics & Dashboard tracks user queries, common topics, and unanswered queries for human analysis and refinement. The legend categorizes the architecture components into generative steps, functions/APIs, databases, and servers.\\n\\nDoc_id: chatbot/backend/sample_images/archi.png \\n Description: The image outlines the architecture of a RAG (Retrieval-Augmented Generation) system. The RAG Workflow involves users interacting with a chatbot that queries a Milvus Vector Database for relevant information. The database ingests various document types (FAQs, emails, PPTX, PDFs, and Excel files) and retrieves top K similar chunks for the query. The chatbot stores user chat history in a Firebase Relational Database. The Deployment and Scaling section shows users interacting with a load balancer that routes queries to RAG servers. Analytics & Dashboard tracks user queries, common topics, and unanswered queries for human analysis and refinement. The legend categorizes the architecture components into generative steps, functions/APIs, databases, and servers.\\n\\nDoc_id: chatbot/backend/sample_images/34.png \\n Description: The graph shows that more voters believe it really matters who wins the presidency than at any point in the last 20 years. In 2000, 50% of registered voters believed it really mattered who won the presidential election, while 44% believed things would be pretty much the same regardless of who was elected. By 2020, 83% of registered voters believed it really mattered who won the presidential election, while only 16% believed things would be pretty much the same regardless of who was elected.'}\n"
     ]
    }
   ],
   "source": [
    "# Test Hybrid Search\n",
    "response = requests.post(url, json=data)\n",
    "if response.status_code == 200:\n",
    "    print(\"Data ingested successfully\")\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"Failed to ingest data: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doc_id: chatbot/backend/sample_images/archi.png \\n Description: The image outlines the architecture of a RAG (Retrieval-Augmented Generation) system. The RAG Workflow involves users interacting with a chatbot that queries a Milvus Vector Database for relevant information. The database ingests various document types (FAQs, emails, PPTX, PDFs, and Excel files) and retrieves top K similar chunks for the query. The chatbot stores user chat history in a Firebase Relational Database. The Deployment and Scaling section shows users interacting with a load balancer that routes queries to RAG servers. Analytics & Dashboard tracks user queries, common topics, and unanswered queries for human analysis and refinement. The legend categorizes the architecture components into generative steps, functions/APIs, databases, and servers.\\n\\nDoc_id: chatbot/backend/sample_images/archi.png \\n Description: The image outlines the architecture of a RAG (Retrieval-Augmented Generation) system. The RAG Workflow involves users interacting with a chatbot that queries a Milvus Vector Database for relevant information. The database ingests various document types (FAQs, emails, PPTX, PDFs, and Excel files) and retrieves top K similar chunks for the query. The chatbot stores user chat history in a Firebase Relational Database. The Deployment and Scaling section shows users interacting with a load balancer that routes queries to RAG servers. Analytics & Dashboard tracks user queries, common topics, and unanswered queries for human analysis and refinement. The legend categorizes the architecture components into generative steps, functions/APIs, databases, and servers.\\n\\nDoc_id: chatbot/backend/sample_images/archi.png \\n Description: The image outlines the architecture of a RAG (Retrieval-Augmented Generation) system. The RAG Workflow involves users interacting with a chatbot that queries a Milvus Vector Database for relevant information. The database ingests various document types (FAQs, emails, PPTX, PDFs, and Excel files) and retrieves top K similar chunks for the query. The chatbot stores user chat history in a Firebase Relational Database. The Deployment and Scaling section shows users interacting with a load balancer that routes queries to RAG servers. Analytics & Dashboard tracks user queries, common topics, and unanswered queries for human analysis and refinement. The legend categorizes the architecture components into generative steps, functions/APIs, databases, and servers.\\n\\nDoc_id: chatbot/backend/sample_images/archi.png \\n Description: The image outlines the architecture of a RAG (Retrieval-Augmented Generation) system. The RAG Workflow involves users interacting with a chatbot that queries a Milvus Vector Database for relevant information. The database ingests various document types (FAQs, emails, PPTX, PDFs, and Excel files) and retrieves top K similar chunks for the query. The chatbot stores user chat history in a Firebase Relational Database. The Deployment and Scaling section shows users interacting with a load balancer that routes queries to RAG servers. Analytics & Dashboard tracks user queries, common topics, and unanswered queries for human analysis and refinement. The legend categorizes the architecture components into generative steps, functions/APIs, databases, and servers.\\n\\nDoc_id: chatbot/backend/sample_images/34.png \\n Description: The graph shows that more voters believe it really matters who wins the presidency than at any point in the last 20 years. In 2000, 50% of registered voters believed it really mattered who won the presidential election, while 44% believed things would be pretty much the same regardless of who was elected. By 2020, 83% of registered voters believed it really mattered who won the presidential election, while only 16% believed things would be pretty much the same regardless of who was elected.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odprt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
