{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Functions\n",
    "1. `parse_for_ingestion`: Parsing for ingestion (more specific and intentional)\n",
    "2. `parse_user_files`: Parsing for user routing (general, not as important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (exc.py, line 258)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3526\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[3], line 3\u001b[0m\n    from llama_parse import LlamaParse\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_parse/__init__.py:1\u001b[0m\n    from llama_cloud_services.parse import LlamaParse, ResultType\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_cloud_services/__init__.py:1\u001b[0m\n    from llama_cloud_services.parse import LlamaParse\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_cloud_services/parse/__init__.py:1\u001b[0m\n    from llama_cloud_services.parse.base import LlamaParse, ResultType\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_cloud_services/parse/base.py:14\u001b[0m\n    from llama_index.core.async_utils import asyncio_run, run_jobs\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/__init__.py:25\u001b[0m\n    from llama_index.core.indices import (\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/__init__.py:32\u001b[0m\n    from llama_index.core.indices.loading import (\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/loading.py:6\u001b[0m\n    from llama_index.core.indices.registry import INDEX_STRUCT_TYPE_TO_INDEX_CLASS\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/registry.py:12\u001b[0m\n    from llama_index.core.indices.multi_modal import MultiModalVectorStoreIndex\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/multi_modal/__init__.py:3\u001b[0m\n    from llama_index.core.indices.multi_modal.base import MultiModalVectorStoreIndex\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/multi_modal/base.py:29\u001b[0m\n    from llama_index.core.query_engine.multi_modal import SimpleMultiModalQueryEngine\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/query_engine/__init__.py:4\u001b[0m\n    from llama_index.core.indices.struct_store.sql_query import (\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/struct_store/__init__.py:8\u001b[0m\n    from llama_index.core.indices.struct_store.sql import (\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/struct_store/sql.py:11\u001b[0m\n    from llama_index.core.indices.common.struct_store.sql import (\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/common/struct_store/sql.py:6\u001b[0m\n    from llama_index.core.indices.common.struct_store.base import (\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/indices/common/struct_store/base.py:24\u001b[0m\n    from llama_index.core.utilities.sql_wrapper import SQLDatabase\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/llama_index/core/utilities/sql_wrapper.py:5\u001b[0m\n    from sqlalchemy import MetaData, create_engine, insert, inspect, text\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/sqlalchemy/__init__.py:10\u001b[0;36m\n\u001b[0;31m    import sqlalchemy.exc as exceptions\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/sqlalchemy/exc.py:258\u001b[0;36m\u001b[0m\n\u001b[0;31m    except Exception, e:\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import fitz\n",
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved image: output_images/page_3_figure_1.png\n",
      "✔ Saved image: output_images/page_3_figure_2.png\n",
      "✔ Saved image: output_images/page_5_figure_1.png\n",
      "✔ Saved image: output_images/page_5_figure_2.png\n",
      "✔ Saved image: output_images/page_5_figure_3.png\n",
      "✔ Saved image: output_images/page_5_figure_4.png\n",
      "✔ Saved image: output_images/page_5_figure_5.png\n",
      "✔ Saved image: output_images/page_5_figure_6.png\n",
      "✔ Saved image: output_images/page_5_figure_7.png\n",
      "✔ Saved image: output_images/page_5_figure_8.png\n",
      "✔ Saved image: output_images/page_5_figure_9.png\n",
      "✔ Saved image: output_images/page_5_figure_10.png\n",
      "✔ Saved image: output_images/page_5_figure_11.png\n",
      "✔ Saved image: output_images/page_5_figure_12.png\n",
      "✔ Saved image: output_images/page_5_figure_13.png\n",
      "✔ Saved image: output_images/page_5_figure_14.png\n",
      "✔ Saved image: output_images/page_5_figure_15.png\n",
      "✔ Saved image: output_images/page_5_figure_16.png\n",
      "✔ Saved image: output_images/page_5_figure_17.png\n",
      "✔ Saved image: output_images/page_5_figure_18.png\n",
      "✔ Saved image: output_images/page_5_figure_19.png\n",
      "✔ Saved image: output_images/page_5_figure_20.png\n",
      "✔ Saved image: output_images/page_5_figure_21.png\n",
      "✔ Saved image: output_images/page_5_figure_22.png\n",
      "✔ Saved image: output_images/page_5_figure_23.png\n",
      "✔ Saved image: output_images/page_5_figure_24.png\n",
      "✔ Saved image: output_images/page_5_figure_25.png\n",
      "✔ Saved image: output_images/page_5_figure_26.png\n",
      "✔ Saved image: output_images/page_5_figure_27.png\n",
      "✔ Saved image: output_images/page_5_figure_28.png\n",
      "✔ Saved image: output_images/page_5_figure_29.png\n",
      "✔ Saved image: output_images/page_5_figure_30.png\n",
      "✔ Saved image: output_images/page_5_figure_31.png\n",
      "✔ Saved image: output_images/page_5_figure_32.png\n",
      "✔ Saved image: output_images/page_5_figure_33.png\n",
      "✔ Saved image: output_images/page_5_figure_34.png\n",
      "✔ Saved image: output_images/page_5_figure_35.png\n",
      "✔ Saved image: output_images/page_5_figure_36.png\n",
      "✔ Saved image: output_images/page_5_figure_37.png\n",
      "✔ Saved image: output_images/page_5_figure_38.png\n",
      "✔ Saved image: output_images/page_5_figure_39.png\n",
      "✔ Saved image: output_images/page_5_figure_40.png\n",
      "✔ Saved image: output_images/page_5_figure_41.png\n",
      "✔ Saved image: output_images/page_5_figure_42.png\n",
      "✔ Saved image: output_images/page_5_figure_43.png\n",
      "✔ Saved image: output_images/page_5_figure_44.png\n",
      "✔ Saved image: output_images/page_5_figure_45.png\n",
      "✔ Saved image: output_images/page_6_figure_1.png\n",
      "✔ Saved image: output_images/page_13_figure_1.png\n",
      "✔ Saved image: output_images/page_13_figure_2.png\n",
      "✔ Saved image: output_images/page_13_figure_3.png\n",
      "✔ Saved image: output_images/page_15_figure_1.png\n",
      "✔ Saved image: output_images/page_15_figure_2.png\n",
      "✔ Saved image: output_images/page_15_figure_3.png\n",
      "✔ Saved image: output_images/page_15_figure_4.png\n",
      "✔ Saved image: output_images/page_15_figure_5.png\n",
      "✔ Saved image: output_images/page_15_figure_6.png\n",
      "✔ Saved image: output_images/page_15_figure_7.png\n",
      "✔ Saved image: output_images/page_15_figure_8.png\n",
      "✔ Saved image: output_images/page_15_figure_9.png\n",
      "✔ Saved image: output_images/page_15_figure_10.png\n",
      "✔ Saved image: output_images/page_16_figure_1.png\n",
      "Extracted 62 images.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def extract_images_from_pdf(pdf_path, output_folder=\"extracted_images\", min_contour_area=5000):\n",
    "    \"\"\"\n",
    "    Extracts images from a rendered PDF file using OpenCV.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        output_folder (str): Directory to save extracted images.\n",
    "        min_contour_area (int): Minimum area size to detect images.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of saved image file paths.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create folder if it doesn’t exist\n",
    "    poppler_path = \"/opt/homebrew/bin\"  # Adjust this for your system\n",
    "\n",
    "    images = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)  # Render PDF pages to images\n",
    "    extracted_images = []\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        open_cv_image = np.array(image)  # Convert to NumPy array\n",
    "        open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply threshold to separate text from images\n",
    "        _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        figure_count = 0  # Track number of extracted images per page\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < min_contour_area:  # Ignore small contours (noise)\n",
    "                continue\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(contour)  # Get bounding box\n",
    "            cropped_image = open_cv_image[y:y + h, x:x + w]  # Crop detected figure\n",
    "\n",
    "            # Save image\n",
    "            image_filename = f\"page_{page_num+1}_figure_{figure_count+1}.png\"\n",
    "            image_path = os.path.join(output_folder, image_filename)\n",
    "            cv2.imwrite(image_path, cropped_image)  # Save image using OpenCV\n",
    "\n",
    "            extracted_images.append(image_path)\n",
    "            print(f\"✔ Saved image: {image_path}\")\n",
    "\n",
    "            figure_count += 1\n",
    "\n",
    "    return extracted_images\n",
    "\n",
    "# Example usage:\n",
    "pdf_file = \"/Users/lishuyao/Documents/NUS/MODS/Y3S2/Capstone/ODPRT-chatbot/notebooks/1810.04805v2.pdf\"\n",
    "output_dir = \"output_images\"\n",
    "extracted_images = extract_images_from_pdf(pdf_file, output_dir)\n",
    "\n",
    "print(f\"Extracted {len(extracted_images)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "test_image = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "test_image_bgr = cv.cvtColor(test_image, cv.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 69\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extracted_figures\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Extract text and figures\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# text_data = extract_combined_text_from_pdf(pdf_path, output_text_file)\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m figure_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_figures_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_figures_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Combine results in a dictionary\u001b[39;00m\n\u001b[1;32m     72\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# \"text\": text_data,\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigures\u001b[39m\u001b[38;5;124m\"\u001b[39m: figure_data\n\u001b[1;32m     75\u001b[0m }\n",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m, in \u001b[0;36mextract_figures_from_pdf\u001b[0;34m(pdf_path, output_folder, min_contour_area)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_num, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Convert image to OpenCV format\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     open_cv_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)\n\u001b[0;32m---> 38\u001b[0m     open_cv_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopen_cv_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB2BGR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Convert to grayscale and apply edge detection\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(open_cv_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths\n",
    "pdf_path = \"1810.04805v2.pdf\"\n",
    "# output_text_file = \"/data/combined_text.txt\"\n",
    "output_figures_folder = \"data/extracted_figures\"\n",
    "\n",
    "# Create output directories\n",
    "# os.makedirs(os.path.dirname(output_text_file), exist_ok=True)\n",
    "os.makedirs(output_figures_folder, exist_ok=True)\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_combined_text_from_pdf(pdf_path, output_file_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "        for page_num in range(len(doc)):\n",
    "            text = doc[page_num].get_text(\"text\")\n",
    "            text_file.write(f\"\\n\\n--- Page {page_num+1} ---\\n\\n\")\n",
    "            text_file.write(text)\n",
    "\n",
    "    return output_file_path\n",
    "\n",
    "# Function to extract figures from PDF\n",
    "poppler_path = \"/opt/homebrew/bin\"  # Adjust this if needed\n",
    "def extract_figures_from_pdf(pdf_path, output_folder, min_contour_area=5000):\n",
    "    images = convert_from_path(pdf_path,  poppler_path = poppler_path)\n",
    "    extracted_figures = {}\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        # Convert image to OpenCV format\n",
    "        open_cv_image = np.array(image)\n",
    "        open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Convert to grayscale and apply edge detection\n",
    "        gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        figure_paths = []\n",
    "        figure_count = 0\n",
    "\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < min_contour_area:\n",
    "                continue\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            figure_image = image.crop((x, y, x + w, y + h))\n",
    "\n",
    "            figure_path = os.path.join(output_folder, f\"page_{page_num+1}_figure_{figure_count+1}.png\")\n",
    "            figure_image.save(figure_path, \"PNG\")\n",
    "            figure_paths.append(figure_path)\n",
    "\n",
    "            figure_count += 1\n",
    "\n",
    "        extracted_figures[f\"Page {page_num+1}\"] = figure_paths\n",
    "\n",
    "    return extracted_figures\n",
    "\n",
    "# Extract text and figures\n",
    "# text_data = extract_combined_text_from_pdf(pdf_path, output_text_file)\n",
    "figure_data = extract_figures_from_pdf(pdf_path, output_figures_folder)\n",
    "\n",
    "# Combine results in a dictionary\n",
    "extracted_data = {\n",
    "    # \"text\": text_data,\n",
    "    \"figures\": figure_data\n",
    "}\n",
    "\n",
    "# Return the extracted paths\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 92\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extracted_images\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Extract text and figures\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# text_data = extract_combined_text_from_pdf(pdf_path, output_text_file)\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m figure_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_figures_and_tables_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_figures_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Combine results in a dictionary\u001b[39;00m\n\u001b[1;32m     95\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# \"text\": text_data,\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigures\u001b[39m\u001b[38;5;124m\"\u001b[39m: figure_data\n\u001b[1;32m     98\u001b[0m }\n",
      "Cell \u001b[0;32mIn[9], line 42\u001b[0m, in \u001b[0;36mextract_figures_and_tables_from_pdf\u001b[0;34m(pdf_path, output_folder, min_contour_area, min_table_area)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_num, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Convert image to OpenCV format\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     open_cv_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)\n\u001b[0;32m---> 42\u001b[0m     open_cv_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopen_cv_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB2BGR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(open_cv_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths\n",
    "pdf_path = \"1810.04805v2.pdf\"\n",
    "output_text_file = \"data/combined_text.txt\"\n",
    "output_figures_folder = \"data/extracted_figures\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.dirname(output_text_file), exist_ok=True)\n",
    "os.makedirs(output_figures_folder, exist_ok=True)\n",
    "\n",
    "# # Function to extract text from PDF\n",
    "# def extract_combined_text_from_pdf(pdf_path, output_file_path):\n",
    "#     doc = fitz.open(pdf_path)\n",
    "    \n",
    "#     with open(output_file_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "#         for page_num in range(len(doc)):\n",
    "#             text = doc[page_num].get_text(\"text\")\n",
    "#             text_file.write(f\"\\n\\n--- Page {page_num+1} ---\\n\\n\")\n",
    "#             text_file.write(text)\n",
    "\n",
    "#     return output_file_path\n",
    "\n",
    "# Function to extract figures from PDF\n",
    "poppler_path = \"/opt/homebrew/bin\"  # Adjust this if needed\n",
    "\n",
    "def extract_figures_and_tables_from_pdf(pdf_path, output_folder, min_contour_area=5000, min_table_area=10000):\n",
    "    images = convert_from_path(pdf_path, poppler_path=poppler_path)  # Convert PDF pages to images\n",
    "    extracted_images = {}\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        # Convert image to OpenCV format\n",
    "        open_cv_image = np.array(image)\n",
    "        open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply adaptive thresholding to detect tables\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4)\n",
    "\n",
    "        # Detect vertical and horizontal lines to identify tables\n",
    "        kernel_h = np.ones((1, 10), np.uint8)\n",
    "        kernel_v = np.ones((10, 1), np.uint8)\n",
    "        horizontal_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_h)\n",
    "        vertical_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_v)\n",
    "        table_mask = cv2.add(horizontal_lines, vertical_lines)\n",
    "\n",
    "        # Find contours for tables and figures\n",
    "        contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        figure_paths = []\n",
    "        table_paths = []\n",
    "        count_figures = 0\n",
    "        count_tables = 0\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            if cv2.contourArea(contour) > min_table_area:\n",
    "                # Extract tables\n",
    "                table_image = image.crop((x, y, x + w, y + h))\n",
    "                table_path = os.path.join(output_folder, f\"page_{page_num+1}_table_{count_tables+1}.png\")\n",
    "                table_image.save(table_path, \"PNG\")\n",
    "                table_paths.append(table_path)\n",
    "                count_tables += 1\n",
    "            elif cv2.contourArea(contour) > min_contour_area:\n",
    "                # Extract figures\n",
    "                figure_image = image.crop((x, y, x + w, y + h))\n",
    "                figure_path = os.path.join(output_folder, f\"page_{page_num+1}_figure_{count_figures+1}.png\")\n",
    "                figure_image.save(figure_path, \"PNG\")\n",
    "                figure_paths.append(figure_path)\n",
    "                count_figures += 1\n",
    "\n",
    "        extracted_images[f\"Page {page_num+1}\"] = {\n",
    "            \"figures\": figure_paths,\n",
    "            \"tables\": table_paths\n",
    "        }\n",
    "\n",
    "    return extracted_images\n",
    "\n",
    "# Extract text and figures\n",
    "# text_data = extract_combined_text_from_pdf(pdf_path, output_text_file)\n",
    "figure_data = extract_figures_and_tables_from_pdf(pdf_path, output_figures_folder)\n",
    "\n",
    "# Combine results in a dictionary\n",
    "extracted_data = {\n",
    "    # \"text\": text_data,\n",
    "    \"figures\": figure_data\n",
    "}\n",
    "\n",
    "# Return the extracted paths\n",
    "print(extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted files: {'Page 1': {'figures': [], 'tables': []}, 'Page 2': {'figures': [], 'tables': []}, 'Page 3': {'figures': [], 'tables': []}, 'Page 4': {'figures': ['data/extracted_content/page_4_figure_1.png', 'data/extracted_content/page_4_figure_2.png', 'data/extracted_content/page_4_figure_3.png', 'data/extracted_content/page_4_figure_4.png'], 'tables': []}, 'Page 5': {'figures': ['data/extracted_content/page_5_figure_1.png'], 'tables': []}, 'Page 6': {'figures': ['data/extracted_content/page_6_figure_1.png', 'data/extracted_content/page_6_figure_2.png'], 'tables': []}, 'Page 7': {'figures': ['data/extracted_content/page_7_figure_1.png'], 'tables': []}, 'Page 8': {'figures': [], 'tables': []}, 'Page 9': {'figures': [], 'tables': []}, 'Page 10': {'figures': ['data/extracted_content/page_10_figure_1.png'], 'tables': []}, 'Page 11': {'figures': ['data/extracted_content/page_11_figure_1.png'], 'tables': []}, 'Page 12': {'figures': ['data/extracted_content/page_12_figure_1.png'], 'tables': []}, 'Page 13': {'figures': [], 'tables': []}, 'Page 14': {'figures': [], 'tables': []}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def extract_clean_images_from_pdf(pdf_path, output_folder,\n",
    "                                  min_contour_area=10000,  # Minimum size for valid content\n",
    "                                  max_logo_area=60000,  # Max size for headers/logos\n",
    "                                  header_threshold=100,  # Ignore anything at the top of the page\n",
    "                                  signature_aspect_ratio=(4, 15),  # Aspect ratio to detect signatures\n",
    "                                  signature_max_height=100):  # Max height for signatures\n",
    "    \"\"\"\n",
    "    Extracts figures and tables from a PDF while removing headers, logos, and signatures.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        output_folder (str): Folder to save extracted images.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted images per page.\n",
    "    \"\"\"\n",
    "\n",
    "    images = convert_from_path(pdf_path, poppler_path=\"/opt/homebrew/bin\")  # Convert PDF to images\n",
    "    extracted_data = {}\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, image in enumerate(images):\n",
    "            page = pdf.pages[page_num]\n",
    "\n",
    "            # Convert image to OpenCV format\n",
    "            open_cv_image = np.array(image)\n",
    "            open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "            gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # **Detect Tables with pdfplumber**\n",
    "            tables = page.extract_tables()\n",
    "            table_paths = []\n",
    "\n",
    "            if tables:\n",
    "                for i, table in enumerate(tables):\n",
    "                    table_path = os.path.join(output_folder, f\"page_{page_num+1}_table_{i+1}.png\")\n",
    "\n",
    "                    # Convert table to an image using PIL\n",
    "                    table_img = Image.new(\"RGB\", (1000, 30 * len(table)), \"white\")\n",
    "                    draw = ImageDraw.Draw(table_img)\n",
    "\n",
    "                    for row_idx, row in enumerate(table):\n",
    "                        row_text = \" | \".join(str(cell) if cell is not None else \"\" for cell in row)\n",
    "                        draw.text((10, 30 * row_idx), row_text, fill=\"black\")\n",
    "\n",
    "                    table_img.save(table_path, \"PNG\")\n",
    "                    table_paths.append(table_path)\n",
    "\n",
    "            # **Detect Figures with OpenCV**\n",
    "            edges = cv2.Canny(gray, 50, 150)  # Detect edges\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            figure_paths = []\n",
    "            figure_count = 0\n",
    "\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                area = w * h\n",
    "                aspect_ratio = w / h if h > 0 else 0  # Prevent division by zero\n",
    "\n",
    "                # **Ignore headers and logos** (small, high-up elements)\n",
    "                if area < max_logo_area and y < header_threshold:\n",
    "                    continue  \n",
    "\n",
    "                # **Ignore signatures** (long, narrow elements at the bottom)\n",
    "                if signature_aspect_ratio[0] < aspect_ratio < signature_aspect_ratio[1] and h < signature_max_height:\n",
    "                    continue  \n",
    "\n",
    "                if area > min_contour_area:  \n",
    "                    figure_image = image.crop((x, y, x + w, y + h))\n",
    "                    figure_path = os.path.join(output_folder, f\"page_{page_num+1}_figure_{figure_count+1}.png\")\n",
    "                    figure_image.save(figure_path, \"PNG\")\n",
    "                    figure_paths.append(figure_path)\n",
    "                    figure_count += 1\n",
    "\n",
    "            extracted_data[f\"Page {page_num+1}\"] = {\n",
    "                \"figures\": figure_paths,\n",
    "                \"tables\": table_paths\n",
    "            }\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "# **Example Usage**\n",
    "pdf_path = \"/Users/lishuyao/Documents/NUS/MODS/Y3S2/Capstone/ODPRT-chatbot/processed_docs/emails_with_attachments/Agreement Type 01-01/processed_attachments/2018-1323 PA NUS-HDB (Fully Executed)_processed_processed.pdf\"\n",
    "output_folder = \"data/extracted_content\"\n",
    "\n",
    "extracted_data = extract_clean_images_from_pdf(pdf_path, output_folder)\n",
    "\n",
    "print(\"✅ Extracted files:\", extracted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found pdf\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'extract_images_from_pdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m             store[fname] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m\"\u001b[39m: tables, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images} \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m store\n\u001b[0;32m---> 19\u001b[0m \u001b[43mparse_for_ingestion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1810.04805v2.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36mparse_for_ingestion\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m     13\u001b[0m         text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(fname)\n\u001b[1;32m     14\u001b[0m         tables \u001b[38;5;241m=\u001b[39m extract_tables_from_pdf(fname)\n\u001b[0;32m---> 15\u001b[0m         images \u001b[38;5;241m=\u001b[39m \u001b[43mextract_images_from_pdf\u001b[49m(fname)\n\u001b[1;32m     16\u001b[0m         store[fname] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m\"\u001b[39m: tables, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images} \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_images_from_pdf' is not defined"
     ]
    }
   ],
   "source": [
    "def parse_for_ingestion(files):\n",
    "    # parser = LlamaParse(\n",
    "    # api_key=\"(Your API key here)\",\n",
    "    # result_type=\"markdown\"\n",
    "    # )\n",
    "\n",
    "    store = {}\n",
    "    # documents = await parser.aload_data('/sample report')\n",
    "    \n",
    "    for fname in files:\n",
    "        if fname.endswith('.pdf'):\n",
    "            print(\"found pdf\")\n",
    "            text = extract_text_from_pdf(fname)\n",
    "            tables = extract_tables_from_pdf(fname)\n",
    "            images = extract_images_from_pdf(fname)\n",
    "            store[fname] = {\"text\": text, \"tables\": tables, \"images\": images} \n",
    "    return store\n",
    "\n",
    "parse_for_ingestion([\"1810.04805v2.pdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markitdown\n",
      "  Obtaining dependency information for markitdown from https://files.pythonhosted.org/packages/5f/24/f2de79bc50c82d63d243834b67af4ed3ae8b8bf71652aecc6118d4d1a306/markitdown-0.0.1a4-py3-none-any.whl.metadata\n",
      "  Downloading markitdown-0.0.1a4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting azure-ai-documentintelligence (from markitdown)\n",
      "  Obtaining dependency information for azure-ai-documentintelligence from https://files.pythonhosted.org/packages/84/a8/c9c66d4d04b8aee06ebdc9a6077736b222b9b2fe92364fed6f9a1c08ece0/azure_ai_documentintelligence-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading azure_ai_documentintelligence-1.0.0-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-identity (from markitdown)\n",
      "  Obtaining dependency information for azure-identity from https://files.pythonhosted.org/packages/de/aa/819513c1dbef990af690bb5eefb5e337f8698d75dfdb7302528f50ce1994/azure_identity-1.20.0-py3-none-any.whl.metadata\n",
      "  Downloading azure_identity-1.20.0-py3-none-any.whl.metadata (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from markitdown) (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from markitdown) (2.0.4)\n",
      "Collecting mammoth (from markitdown)\n",
      "  Obtaining dependency information for mammoth from https://files.pythonhosted.org/packages/d0/ab/f8e63fcabc127c6efd68b03633c189ee799a5304fa96c036a325a2894bcb/mammoth-1.9.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading mammoth-1.9.0-py2.py3-none-any.whl.metadata (24 kB)\n",
      "Collecting markdownify (from markitdown)\n",
      "  Obtaining dependency information for markdownify from https://files.pythonhosted.org/packages/65/0b/74cec93a7b05edf4fc3ea1c899fe8a37f041d7b9d303c75abf7a162924e0/markdownify-0.14.1-py3-none-any.whl.metadata\n",
      "  Downloading markdownify-0.14.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from markitdown) (1.25.2)\n",
      "Collecting olefile (from markitdown)\n",
      "  Obtaining dependency information for olefile from https://files.pythonhosted.org/packages/17/d3/b64c356a907242d719fc668b71befd73324e47ab46c8ebbbede252c154b2/olefile-0.47-py2.py3-none-any.whl.metadata\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: openai in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from markitdown) (1.29.0)\n",
      "Requirement already satisfied: openpyxl in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from markitdown) (3.1.2)\n",
      "Requirement already satisfied: pandas in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from markitdown) (2.0.3)\n",
      "Collecting pathvalidate (from markitdown)\n",
      "  Obtaining dependency information for pathvalidate from https://files.pythonhosted.org/packages/50/14/c5a0e1a947909810fc4c043b84cac472b70e438148d34f5393be1bac663f/pathvalidate-3.2.3-py3-none-any.whl.metadata\n",
      "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pdfminer-six (from markitdown)\n",
      "  Obtaining dependency information for pdfminer-six from https://files.pythonhosted.org/packages/67/7d/44d6b90e5a293d3a975cefdc4e12a932ebba814995b2a07e37e599dd27c6/pdfminer.six-20240706-py3-none-any.whl.metadata\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting puremagic (from markitdown)\n",
      "  Obtaining dependency information for puremagic from https://files.pythonhosted.org/packages/c5/53/200a97332d10ed3edd7afcbc5f5543920ac59badfe5762598327999f012e/puremagic-1.28-py3-none-any.whl.metadata\n",
      "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting pydub (from markitdown)\n",
      "  Obtaining dependency information for pydub from https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-pptx (from markitdown)\n",
      "  Obtaining dependency information for python-pptx from https://files.pythonhosted.org/packages/d9/4f/00be2196329ebbff56ce564aa94efb0fbc828d00de250b1980de1a34ab49/python_pptx-1.0.2-py3-none-any.whl.metadata\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: requests in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from markitdown) (2.31.0)\n",
      "Collecting speechrecognition (from markitdown)\n",
      "  Obtaining dependency information for speechrecognition from https://files.pythonhosted.org/packages/09/47/5dcfcd8a2c8c2981986fc196e98fc57bc1ecb5233b2d54dac0c0d448b019/SpeechRecognition-3.14.1-py3-none-any.whl.metadata\n",
      "  Downloading SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting xlrd (from markitdown)\n",
      "  Obtaining dependency information for xlrd from https://files.pythonhosted.org/packages/a6/0c/c2a72d51fe56e08a08acc85d13013558a2d793028ae7385448a6ccdfae64/xlrd-2.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting youtube-transcript-api (from markitdown)\n",
      "  Obtaining dependency information for youtube-transcript-api from https://files.pythonhosted.org/packages/80/d4/be6fd091d29ae49d93813e598769e7ab453419a4de640e1755bf20911cce/youtube_transcript_api-0.6.3-py3-none-any.whl.metadata\n",
      "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting isodate>=0.6.1 (from azure-ai-documentintelligence->markitdown)\n",
      "  Obtaining dependency information for isodate>=0.6.1 from https://files.pythonhosted.org/packages/15/aa/0aca39a37d3c7eb941ba736ede56d689e7be91cab5d9ca846bde3999eba6/isodate-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-core>=1.30.0 (from azure-ai-documentintelligence->markitdown)\n",
      "  Obtaining dependency information for azure-core>=1.30.0 from https://files.pythonhosted.org/packages/39/83/325bf5e02504dbd8b4faa98197a44cdf8a325ef259b48326a2b6f17f8383/azure_core-1.32.0-py3-none-any.whl.metadata\n",
      "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from azure-ai-documentintelligence->markitdown) (4.10.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from azure-identity->markitdown) (41.0.2)\n",
      "Collecting msal>=1.30.0 (from azure-identity->markitdown)\n",
      "  Obtaining dependency information for msal>=1.30.0 from https://files.pythonhosted.org/packages/30/7c/489cd931a752d05753d730e848039f08f65f86237cf1b8724d0a1cbd700b/msal-1.31.1-py3-none-any.whl.metadata\n",
      "  Downloading msal-1.31.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity->markitdown)\n",
      "  Obtaining dependency information for msal-extensions>=1.2.0 from https://files.pythonhosted.org/packages/2c/69/314d887a01599669fb330da14e5c6ff5f138609e322812a942a74ef9b765/msal_extensions-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from beautifulsoup4->markitdown) (2.4)\n",
      "Collecting cobble<0.2,>=0.1.3 (from mammoth->markitdown)\n",
      "  Obtaining dependency information for cobble<0.2,>=0.1.3 from https://files.pythonhosted.org/packages/d5/e1/3714a2f371985215c219c2a70953d38e3eed81ef165aed061d21de0e998b/cobble-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading cobble-0.1.4-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: six<2,>=1.15 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from markdownify->markitdown) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from openai->markitdown) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from openai->markitdown) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from openai->markitdown) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from openai->markitdown) (2.6.0)\n",
      "Requirement already satisfied: sniffio in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from openai->markitdown) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from openai->markitdown) (4.66.1)\n",
      "Requirement already satisfied: et-xmlfile in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from openpyxl->markitdown) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from pandas->markitdown) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from pandas->markitdown) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from pandas->markitdown) (2023.3)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from python-pptx->markitdown) (9.4.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx->markitdown)\n",
      "  Obtaining dependency information for XlsxWriter>=0.5.7 from https://files.pythonhosted.org/packages/9b/07/df054f7413bdfff5e98f75056e4ed0977d0c8716424011fac2587864d1d3/XlsxWriter-3.2.2-py3-none-any.whl.metadata\n",
      "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from python-pptx->markitdown) (4.9.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from requests->markitdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from requests->markitdown) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from requests->markitdown) (2023.7.22)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from youtube-transcript-api->markitdown) (0.7.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity->markitdown) (1.15.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->markitdown) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->markitdown) (0.14.0)\n",
      "Collecting PyJWT[crypto]<3,>=1.0.0 (from msal>=1.30.0->azure-identity->markitdown)\n",
      "  Obtaining dependency information for PyJWT[crypto]<3,>=1.0.0 from https://files.pythonhosted.org/packages/61/ad/689f02752eeec26aed679477e80e632ef1b682313be70793d798c1d5fc8f/PyJWT-2.10.1-py3-none-any.whl.metadata\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity->markitdown)\n",
      "  Obtaining dependency information for portalocker<3,>=1.4 from https://files.pythonhosted.org/packages/9b/fb/a70a4214956182e0d7a9099ab17d50bfcba1056188e9b14f35b9e2b62a0d/portalocker-2.10.1-py3-none-any.whl.metadata\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->markitdown) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->markitdown) (2.16.1)\n",
      "Requirement already satisfied: pycparser in /Users/lishuyao/opt/anaconda3/envs/testing/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->markitdown) (2.21)\n",
      "Downloading markitdown-0.0.1a4-py3-none-any.whl (21 kB)\n",
      "Downloading azure_ai_documentintelligence-1.0.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.5/105.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_identity-1.20.0-py3-none-any.whl (188 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.2/188.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mammoth-1.9.0-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdownify-0.14.1-py3-none-any.whl (11 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cobble-0.1.4-py3-none-any.whl (4.0 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading msal-1.31.1-py3-none-any.whl (113 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Downloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pydub, puremagic, XlsxWriter, xlrd, speechrecognition, PyJWT, portalocker, pathvalidate, olefile, isodate, cobble, youtube-transcript-api, python-pptx, markdownify, mammoth, azure-core, pdfminer-six, azure-ai-documentintelligence, msal, msal-extensions, azure-identity, markitdown\n",
      "Successfully installed PyJWT-2.10.1 XlsxWriter-3.2.2 azure-ai-documentintelligence-1.0.0 azure-core-1.32.0 azure-identity-1.20.0 cobble-0.1.4 isodate-0.7.2 mammoth-1.9.0 markdownify-0.14.1 markitdown-0.0.1a4 msal-1.31.1 msal-extensions-1.2.0 olefile-0.47 pathvalidate-3.2.3 pdfminer-six-20240706 portalocker-2.10.1 puremagic-1.28 pydub-0.25.1 python-pptx-1.0.2 speechrecognition-3.14.1 xlrd-2.0.1 youtube-transcript-api-0.6.3\n"
     ]
    }
   ],
   "source": [
    "! pip install markitdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markitdown import MarkItDown\n",
    "# md = MarkItDown(docintel_endpoint=\"<document_intelligence_endpoint>\")\n",
    "# result = md.convert(\"1810.04805v2.pdf\")\n",
    "# print(result.text_content)\n",
    "markdown_file = \"output.md\"\n",
    "md = MarkItDown() # Set to True to enable plugins\n",
    "result = md.convert(\"1810.04805v2.pdf\")\n",
    "with open(markdown_file, \"w\", encoding=\"utf-8\") as md_file:\n",
    "    md_file.write(result.text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmammoth\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1810.04805v2.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m docx_file:\n\u001b[0;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmammoth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocx_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     markdown_text \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(markdown_text)\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/mammoth/__init__.py:16\u001b[0m, in \u001b[0;36mconvert_to_markdown\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_markdown\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmarkdown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/mammoth/__init__.py:25\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(fileobj, transform_document, id_prefix, include_embedded_style_map, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     transform_document \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: x\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_embedded_style_map:\n\u001b[0;32m---> 25\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedded_style_map\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mread_style_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m options\u001b[38;5;241m.\u001b[39mread_options(kwargs)\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;28;01mlambda\u001b[39;00m convert_options:\n\u001b[1;32m     27\u001b[0m     docx\u001b[38;5;241m.\u001b[39mread(fileobj)\u001b[38;5;241m.\u001b[39mmap(transform_document)\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;28;01mlambda\u001b[39;00m document:\n\u001b[1;32m     28\u001b[0m         conversion\u001b[38;5;241m.\u001b[39mconvert_document_element_to_html(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/mammoth/docx/style_map.py:66\u001b[0m, in \u001b[0;36mread_style_map\u001b[0;34m(fileobj)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_style_map\u001b[39m(fileobj):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mopen_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_file:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m zip_file\u001b[38;5;241m.\u001b[39mexists(_style_map_path):\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m zip_file\u001b[38;5;241m.\u001b[39mread_str(_style_map_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/mammoth/zips.py:9\u001b[0m, in \u001b[0;36mopen_zip\u001b[0;34m(fileobj, mode)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_zip\u001b[39m(fileobj, mode):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _Zip(\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/zipfile.py:1268\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1268\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/zipfile.py:1335\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import mammoth\n",
    "\n",
    "with open(\"1810.04805v2.pdf\", \"rb\") as docx_file:\n",
    "\n",
    "    result = mammoth.convert_to_markdown(docx_file)\n",
    "\n",
    "    markdown_text = result[\"value\"]\n",
    "\n",
    "    print(markdown_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown file saved as output.md\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pdfminer\n",
    "from pdfminer.high_level import extract_text\n",
    "from PIL import Image\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import os\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from PDF\"\"\"\n",
    "    text = extract_text(pdf_path)\n",
    "    return f\"<text>\\n{text.strip()}\\n</text>\\n\\n\"\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path):\n",
    "    \"\"\"Extract tables from PDF and convert them to Markdown\"\"\"\n",
    "    tables_md = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages, start=1):\n",
    "            tables = page.extract_tables()\n",
    "            for table_index, table in enumerate(tables, start=1):\n",
    "                tables_md += f\"<tbl>\\n\"\n",
    "                for row in table:\n",
    "                    row_md = \"| \" + \" | \".join(str(cell) if cell else \" \" for cell in row) + \" |\"\n",
    "                    tables_md += row_md + \"\\n\"\n",
    "                tables_md += \"</tbl>\\n\\n\"\n",
    "    return tables_md\n",
    "\n",
    "def extract_images_from_pdf(pdf_path, output_folder=\"extracted_images\"):\n",
    "    \"\"\"Extract images from PDF and save them\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    images_md = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page_num in range(len(doc)):\n",
    "        for img_index, img in enumerate(doc[page_num].get_images(full=True), start=1):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_filename = f\"{output_folder}/image_{page_num+1}_{img_index}.{image_ext}\"\n",
    "            \n",
    "            with open(image_filename, \"wb\") as f:\n",
    "                f.write(image_bytes)\n",
    "\n",
    "            images_md += f\"<img>{image_filename}</img>\\n\\n\"\n",
    "\n",
    "    return images_md\n",
    "\n",
    "def convert_pdf_to_markdown(pdf_path, output_md):\n",
    "    \"\"\"Convert PDF to Markdown format with relevant tags\"\"\"\n",
    "    markdown_content = \"\"\n",
    "\n",
    "    # Extract text\n",
    "    markdown_content += extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Extract tables\n",
    "    markdown_content += extract_tables_from_pdf(pdf_path)\n",
    "\n",
    "    markdown_content += extract_images_from_pdf(pdf_path)\n",
    "\n",
    "    # Save to Markdown file\n",
    "    with open(output_md, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "\n",
    "    print(f\"Markdown file saved as {output_md}\")\n",
    "\n",
    "pdf_file = \"1810.04805v2.pdf\"  # Replace with your PDF file path\n",
    "markdown_file = \"output.md\"\n",
    "convert_pdf_to_markdown(pdf_file, markdown_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Images: ['1810.04805v2_output/images/page_1.png', '1810.04805v2_output/images/page_2.png', '1810.04805v2_output/images/page_3.png', '1810.04805v2_output/images/page_4.png', '1810.04805v2_output/images/page_5.png', '1810.04805v2_output/images/page_6.png', '1810.04805v2_output/images/page_7.png', '1810.04805v2_output/images/page_8.png', '1810.04805v2_output/images/page_9.png', '1810.04805v2_output/images/page_10.png', '1810.04805v2_output/images/page_11.png', '1810.04805v2_output/images/page_12.png', '1810.04805v2_output/images/page_13.png', '1810.04805v2_output/images/page_14.png', '1810.04805v2_output/images/page_15.png', '1810.04805v2_output/images/page_16.png']\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import fitz  # PyMuPDF for rendering pages as images\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, output_text_file):\n",
    "    \"\"\"Extracts text from PDF and saves it to a text file.\"\"\"\n",
    "    extracted_text = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                extracted_text.append(text)\n",
    "\n",
    "    text_content = \"\\n\\n\".join(extracted_text)\n",
    "    \n",
    "    with open(output_text_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_content)\n",
    "\n",
    "    return output_text_file\n",
    "\n",
    "def extract_tables_and_figures(pdf_path, output_folder):\n",
    "    \"\"\"Takes screenshots of figures and tables and saves them as image files.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    image_paths = []\n",
    "\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document[page_num]\n",
    "        pix = page.get_pixmap(dpi=300)  # High-resolution image\n",
    "        img_path = os.path.join(output_folder, f\"page_{page_num + 1}.png\")\n",
    "        \n",
    "        pix.save(img_path)\n",
    "        image_paths.append(img_path)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    \"\"\"Extracts text and captures tables/figures as images from the PDF.\"\"\"\n",
    "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    output_folder = f\"{base_name}_output\"\n",
    "    \n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Paths for extracted content\n",
    "    text_file_path = os.path.join(output_folder, f\"{base_name}_text.txt\")\n",
    "    image_output_folder = os.path.join(output_folder, \"images\")\n",
    "\n",
    "    # Extract text\n",
    "    text_file = extract_text_from_pdf(pdf_path, text_file_path)\n",
    "\n",
    "    # Extract images (tables/figures)\n",
    "    image_files = extract_tables_and_figures(pdf_path, image_output_folder)\n",
    "\n",
    "    return {\n",
    "        # \"text_file\": text_file,\n",
    "        \"image_files\": image_files\n",
    "    }\n",
    "\n",
    "# Example Usage\n",
    "pdf_path = \"1810.04805v2.pdf\"  # Replace with your PDF file path\n",
    "result = process_pdf(pdf_path)\n",
    "\n",
    "# Output\n",
    "# print(\"Extracted Text File:\", result[\"text_file\"])\n",
    "print(\"Extracted Images:\", result[\"image_files\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pi_heif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition\n\u001b[0;32m----> 3\u001b[0m elements \u001b[38;5;241m=\u001b[39m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1810.04805v2.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m elements]))\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/unstructured/partition/auto.py:211\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(filename, file, encoding, content_type, url, headers, ssl_verify, request_timeout, strategy, skip_infer_table_types, ocr_languages, languages, detect_language_per_element, pdf_infer_table_structure, extract_images_in_pdf, extract_image_block_types, extract_image_block_output_dir, extract_image_block_to_payload, data_source_metadata, metadata_filename, hi_res_model_name, model_name, starting_page_number, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# -- handle PDF/Image partitioning separately because they have a lot of special-case\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# -- parameters. We'll come back to this after sorting out the other file types.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_type \u001b[38;5;241m==\u001b[39m FileType\u001b[38;5;241m.\u001b[39mPDF:\n\u001b[0;32m--> 211\u001b[0m     partition_pdf \u001b[38;5;241m=\u001b[39m \u001b[43mpartitioner_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     elements \u001b[38;5;241m=\u001b[39m partition_pdf(\n\u001b[1;32m    213\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    214\u001b[0m         file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m augment_metadata(elements)\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/unstructured/partition/auto.py:360\u001b[0m, in \u001b[0;36m_PartitionerLoader.get\u001b[0;34m(self, file_type)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# -- if the partitioner is not in the cache, load it; note this raises if one or more of\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# -- the partitioner's dependencies is not installed.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partitioners:\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partitioners[file_type] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_partitioner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partitioners[file_type]\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/unstructured/partition/auto.py:378\u001b[0m, in \u001b[0;36m_PartitionerLoader._load_partitioner\u001b[0;34m(self, file_type)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# -- load the partitioner and return it --\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m file_type\u001b[38;5;241m.\u001b[39mis_partitionable  \u001b[38;5;66;03m# -- would be a programming error if this failed --\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m partitioner_module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartitioner_module_qname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(partitioner_module, file_type\u001b[38;5;241m.\u001b[39mpartitioner_function_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/unstructured/partition/pdf.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LTContainer, LTImage, LTItem, LTTextBox\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_filename\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpi_heif\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_heif_opener\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m PILImage\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pi_heif'"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "\n",
    "elements = partition(filename=\"1810.04805v2.pdf\")\n",
    "print(\"\\n\\n\".join([str(el) for el in elements]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tesseract in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TesseractNotFoundError",
     "evalue": "/usr/bin/tesseract is not installed or it's not in your PATH. See README file for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/pytesseract/pytesseract.py:275\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubprocess_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/subprocess.py:1837\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1836\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/bin/tesseract'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(np\u001b[38;5;241m.\u001b[39marray(image), cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Use OCR to extract text\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m extracted_text \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Use OCR to detect tables as well\u001b[39;00m\n\u001b[1;32m     19\u001b[0m extracted_tables \u001b[38;5;241m=\u001b[39m pytesseract\u001b[38;5;241m.\u001b[39mimage_to_data(gray, output_type\u001b[38;5;241m=\u001b[39mpytesseract\u001b[38;5;241m.\u001b[39mOutput\u001b[38;5;241m.\u001b[39mDICT)\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/pytesseract/pytesseract.py:486\u001b[0m, in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m--> 486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/pytesseract/pytesseract.py:489\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;124;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    484\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    487\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[1;32m    488\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs)},\n\u001b[0;32m--> 489\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    490\u001b[0m }[output_type]()\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/pytesseract/pytesseract.py:352\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[1;32m    342\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    350\u001b[0m     }\n\u001b[0;32m--> 352\u001b[0m     \u001b[43mrun_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    355\u001b[0m         return_bytes,\n\u001b[1;32m    356\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/odprt/lib/python3.9/site-packages/pytesseract/pytesseract.py:280\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n",
      "\u001b[0;31mTesseractNotFoundError\u001b[0m: /usr/bin/tesseract is not installed or it's not in your PATH. See README file for more information."
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "\n",
    "# Load the image\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n",
    "image_path = \"1810.04805v2_output/images/page_9.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert image to grayscale for better OCR accuracy\n",
    "gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Use OCR to extract text\n",
    "extracted_text = pytesseract.image_to_string(gray)\n",
    "\n",
    "# Use OCR to detect tables as well\n",
    "extracted_tables = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "def save_markdown(text, tables, output_md):\n",
    "    \"\"\"Save extracted text and tables in a Markdown file\"\"\"\n",
    "    markdown_content = \"\"\n",
    "\n",
    "    # Add text section\n",
    "    markdown_content += f\"<text>\\n{text.strip()}\\n</text>\\n\\n\"\n",
    "\n",
    "    # Add table section\n",
    "    for table in tables:\n",
    "        markdown_content += \"<tbl>\\n\"\n",
    "        for row in table:\n",
    "            row_md = \"| \" + \" | \".join(str(cell) if cell else \" \" for cell in row) + \" |\"\n",
    "            markdown_content += row_md + \"\\n\"\n",
    "        markdown_content += \"</tbl>\\n\\n\"\n",
    "\n",
    "    # Save to Markdown file\n",
    "    with open(output_md, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "\n",
    "    print(f\"Markdown file saved as {output_md}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from pytesseract) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'level': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5],\n",
       " 'page_num': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'block_num': [0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19,\n",
       "  19],\n",
       " 'par_num': [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'line_num': [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " 'word_num': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8],\n",
       " 'left': [0,\n",
       "  300,\n",
       "  300,\n",
       "  301,\n",
       "  301,\n",
       "  430,\n",
       "  567,\n",
       "  630,\n",
       "  703,\n",
       "  941,\n",
       "  1031,\n",
       "  1173,\n",
       "  301,\n",
       "  301,\n",
       "  508,\n",
       "  583,\n",
       "  803,\n",
       "  944,\n",
       "  1034,\n",
       "  1142,\n",
       "  301,\n",
       "  301,\n",
       "  356,\n",
       "  452,\n",
       "  581,\n",
       "  665,\n",
       "  860,\n",
       "  913,\n",
       "  977,\n",
       "  1117,\n",
       "  301,\n",
       "  301,\n",
       "  434,\n",
       "  488,\n",
       "  644,\n",
       "  732,\n",
       "  938,\n",
       "  1082,\n",
       "  302,\n",
       "  302,\n",
       "  394,\n",
       "  479,\n",
       "  583,\n",
       "  666,\n",
       "  718,\n",
       "  801,\n",
       "  950,\n",
       "  1023,\n",
       "  301,\n",
       "  301,\n",
       "  445,\n",
       "  506,\n",
       "  626,\n",
       "  704,\n",
       "  783,\n",
       "  900,\n",
       "  1045,\n",
       "  301,\n",
       "  301,\n",
       "  445,\n",
       "  548,\n",
       "  600,\n",
       "  707,\n",
       "  811,\n",
       "  936,\n",
       "  1035,\n",
       "  1069,\n",
       "  300,\n",
       "  300,\n",
       "  420,\n",
       "  599,\n",
       "  660,\n",
       "  727,\n",
       "  959,\n",
       "  1042,\n",
       "  1155,\n",
       "  301,\n",
       "  301,\n",
       "  434,\n",
       "  485,\n",
       "  690,\n",
       "  849,\n",
       "  914,\n",
       "  990,\n",
       "  301,\n",
       "  301,\n",
       "  409,\n",
       "  490,\n",
       "  584,\n",
       "  682,\n",
       "  718,\n",
       "  815,\n",
       "  928,\n",
       "  1084,\n",
       "  1137,\n",
       "  301,\n",
       "  301,\n",
       "  432,\n",
       "  629,\n",
       "  825,\n",
       "  1051,\n",
       "  1122,\n",
       "  302,\n",
       "  302,\n",
       "  454,\n",
       "  600,\n",
       "  676,\n",
       "  815,\n",
       "  917,\n",
       "  988,\n",
       "  1117,\n",
       "  301,\n",
       "  301,\n",
       "  505,\n",
       "  721,\n",
       "  1012,\n",
       "  1112,\n",
       "  301,\n",
       "  301,\n",
       "  533,\n",
       "  618,\n",
       "  705,\n",
       "  747,\n",
       "  839,\n",
       "  301,\n",
       "  301,\n",
       "  301,\n",
       "  301,\n",
       "  403,\n",
       "  690,\n",
       "  895,\n",
       "  991,\n",
       "  300,\n",
       "  301,\n",
       "  301,\n",
       "  301,\n",
       "  370,\n",
       "  418,\n",
       "  483,\n",
       "  607,\n",
       "  736,\n",
       "  923,\n",
       "  972,\n",
       "  1032,\n",
       "  1127,\n",
       "  301,\n",
       "  301,\n",
       "  370,\n",
       "  584,\n",
       "  776,\n",
       "  901,\n",
       "  935,\n",
       "  1069,\n",
       "  301,\n",
       "  301,\n",
       "  423,\n",
       "  525,\n",
       "  567,\n",
       "  685,\n",
       "  732,\n",
       "  798,\n",
       "  1009,\n",
       "  1146,\n",
       "  302,\n",
       "  302,\n",
       "  364,\n",
       "  582,\n",
       "  651,\n",
       "  792,\n",
       "  994,\n",
       "  1058,\n",
       "  1096,\n",
       "  302,\n",
       "  302,\n",
       "  432,\n",
       "  530,\n",
       "  713,\n",
       "  778,\n",
       "  1033,\n",
       "  301,\n",
       "  301,\n",
       "  430,\n",
       "  538,\n",
       "  701,\n",
       "  774,\n",
       "  957,\n",
       "  1063,\n",
       "  1137,\n",
       "  301,\n",
       "  301,\n",
       "  443,\n",
       "  585,\n",
       "  662,\n",
       "  802,\n",
       "  1040,\n",
       "  1152,\n",
       "  302,\n",
       "  302,\n",
       "  367,\n",
       "  480,\n",
       "  563,\n",
       "  628,\n",
       "  754,\n",
       "  985,\n",
       "  1053,\n",
       "  1093,\n",
       "  301,\n",
       "  301,\n",
       "  436,\n",
       "  592,\n",
       "  830,\n",
       "  906,\n",
       "  1081,\n",
       "  302,\n",
       "  302,\n",
       "  344,\n",
       "  593,\n",
       "  731,\n",
       "  967,\n",
       "  1024,\n",
       "  1091,\n",
       "  302,\n",
       "  302,\n",
       "  470,\n",
       "  583,\n",
       "  660,\n",
       "  788,\n",
       "  1068,\n",
       "  301,\n",
       "  301,\n",
       "  347,\n",
       "  591,\n",
       "  645,\n",
       "  835,\n",
       "  1105,\n",
       "  1155,\n",
       "  301,\n",
       "  301,\n",
       "  454,\n",
       "  541,\n",
       "  639,\n",
       "  715,\n",
       "  804,\n",
       "  877,\n",
       "  989,\n",
       "  301,\n",
       "  301,\n",
       "  393,\n",
       "  546,\n",
       "  689,\n",
       "  745,\n",
       "  815,\n",
       "  864,\n",
       "  940,\n",
       "  300,\n",
       "  346,\n",
       "  346,\n",
       "  396,\n",
       "  475,\n",
       "  626,\n",
       "  691,\n",
       "  859,\n",
       "  926,\n",
       "  1007,\n",
       "  300,\n",
       "  300,\n",
       "  368,\n",
       "  546,\n",
       "  680,\n",
       "  735,\n",
       "  812,\n",
       "  1079,\n",
       "  301,\n",
       "  301,\n",
       "  426,\n",
       "  664,\n",
       "  798,\n",
       "  888,\n",
       "  1025,\n",
       "  1120,\n",
       "  302,\n",
       "  302,\n",
       "  378,\n",
       "  443,\n",
       "  621,\n",
       "  754,\n",
       "  804,\n",
       "  871,\n",
       "  976,\n",
       "  1024,\n",
       "  1158,\n",
       "  301,\n",
       "  301,\n",
       "  379,\n",
       "  415,\n",
       "  716,\n",
       "  932,\n",
       "  1076,\n",
       "  1158,\n",
       "  301,\n",
       "  301,\n",
       "  452,\n",
       "  525,\n",
       "  702,\n",
       "  899,\n",
       "  1049,\n",
       "  300,\n",
       "  300,\n",
       "  360,\n",
       "  430,\n",
       "  539,\n",
       "  740,\n",
       "  906,\n",
       "  1076,\n",
       "  1143,\n",
       "  301,\n",
       "  301,\n",
       "  436,\n",
       "  514,\n",
       "  563,\n",
       "  594,\n",
       "  741,\n",
       "  825,\n",
       "  895,\n",
       "  951,\n",
       "  1021,\n",
       "  1105,\n",
       "  1125,\n",
       "  357,\n",
       "  357,\n",
       "  372,\n",
       "  372,\n",
       "  357,\n",
       "  357,\n",
       "  455,\n",
       "  528,\n",
       "  601,\n",
       "  667,\n",
       "  766,\n",
       "  931,\n",
       "  1063,\n",
       "  362,\n",
       "  362,\n",
       "  381,\n",
       "  381,\n",
       "  445,\n",
       "  540,\n",
       "  638,\n",
       "  802,\n",
       "  950,\n",
       "  1076,\n",
       "  381,\n",
       "  381,\n",
       "  445,\n",
       "  556,\n",
       "  638,\n",
       "  804,\n",
       "  951,\n",
       "  1075,\n",
       "  381,\n",
       "  381,\n",
       "  445,\n",
       "  540,\n",
       "  637,\n",
       "  804,\n",
       "  951,\n",
       "  1075,\n",
       "  365,\n",
       "  365,\n",
       "  445,\n",
       "  540,\n",
       "  638,\n",
       "  804,\n",
       "  951,\n",
       "  1075,\n",
       "  365,\n",
       "  365,\n",
       "  430,\n",
       "  540,\n",
       "  638,\n",
       "  804,\n",
       "  951,\n",
       "  1075,\n",
       "  362,\n",
       "  362,\n",
       "  430,\n",
       "  540,\n",
       "  638,\n",
       "  804,\n",
       "  951,\n",
       "  1075,\n",
       "  818,\n",
       "  818,\n",
       "  818,\n",
       "  818,\n",
       "  890,\n",
       "  946,\n",
       "  356,\n",
       "  356,\n",
       "  356,\n",
       "  356,\n",
       "  356,\n",
       "  356,\n",
       "  356,\n",
       "  356,\n",
       "  301,\n",
       "  301,\n",
       "  301,\n",
       "  301,\n",
       "  407,\n",
       "  475,\n",
       "  636,\n",
       "  723,\n",
       "  841,\n",
       "  961,\n",
       "  1060,\n",
       "  1122,\n",
       "  1159,\n",
       "  301,\n",
       "  301,\n",
       "  437,\n",
       "  480,\n",
       "  598,\n",
       "  659,\n",
       "  690,\n",
       "  813,\n",
       "  896,\n",
       "  957,\n",
       "  988,\n",
       "  1124,\n",
       "  1167,\n",
       "  301,\n",
       "  301,\n",
       "  425,\n",
       "  543,\n",
       "  633,\n",
       "  740,\n",
       "  776,\n",
       "  836,\n",
       "  971,\n",
       "  1042,\n",
       "  301,\n",
       "  301,\n",
       "  346,\n",
       "  494,\n",
       "  634,\n",
       "  1321,\n",
       "  1321,\n",
       "  1321,\n",
       "  1321,\n",
       "  1321,\n",
       "  1321,\n",
       "  1321,\n",
       "  1321,\n",
       "  1322,\n",
       "  1322,\n",
       "  1323,\n",
       "  1323,\n",
       "  1902,\n",
       "  1973,\n",
       "  2039,\n",
       "  2110,\n",
       "  1322,\n",
       "  1322,\n",
       "  1430,\n",
       "  1542,\n",
       "  1578,\n",
       "  1633,\n",
       "  1925,\n",
       "  2062,\n",
       "  1322,\n",
       "  1322,\n",
       "  1407,\n",
       "  1511,\n",
       "  1547,\n",
       "  1602,\n",
       "  1951,\n",
       "  2062,\n",
       "  1322,\n",
       "  1322,\n",
       "  1401,\n",
       "  1515,\n",
       "  1551,\n",
       "  1606,\n",
       "  1951,\n",
       "  2062,\n",
       "  1322,\n",
       "  1322,\n",
       "  1506,\n",
       "  1353,\n",
       "  1353,\n",
       "  1353,\n",
       "  1447,\n",
       "  1925,\n",
       "  2063,\n",
       "  1322,\n",
       "  1353,\n",
       "  1353,\n",
       "  1445,\n",
       "  1925,\n",
       "  2063,\n",
       "  1322,\n",
       "  1322,\n",
       "  1541,\n",
       "  1688,\n",
       "  1353,\n",
       "  1353,\n",
       "  1353,\n",
       "  1925,\n",
       "  2089,\n",
       "  1354,\n",
       "  1354,\n",
       "  1354,\n",
       "  1590,\n",
       "  1925,\n",
       "  2089,\n",
       "  1353,\n",
       "  1353,\n",
       "  1353,\n",
       "  1426,\n",
       "  1925,\n",
       "  2089,\n",
       "  1352,\n",
       "  1352,\n",
       "  1352,\n",
       "  1352,\n",
       "  1505,\n",
       "  1582,\n",
       "  1656,\n",
       "  1735,\n",
       "  1925,\n",
       "  2089,\n",
       "  1353,\n",
       "  1353,\n",
       "  1468,\n",
       "  1542,\n",
       "  1621,\n",
       "  1925,\n",
       "  2089,\n",
       "  1352,\n",
       "  1352,\n",
       "  1505,\n",
       "  1582,\n",
       "  1643,\n",
       "  1686,\n",
       "  1925,\n",
       "  2089,\n",
       "  1281,\n",
       "  1281,\n",
       "  1281,\n",
       "  1281,\n",
       "  1387,\n",
       "  1439,\n",
       "  1678,\n",
       "  1812,\n",
       "  1928,\n",
       "  2144,\n",
       "  1283,\n",
       "  1283,\n",
       "  1399,\n",
       "  1702,\n",
       "  1800,\n",
       "  1949,\n",
       "  2055,\n",
       "  2122,\n",
       "  1283,\n",
       "  1283,\n",
       "  1350,\n",
       "  1422,\n",
       "  1569,\n",
       "  1646,\n",
       "  1714,\n",
       "  1792,\n",
       "  1903,\n",
       "  1962,\n",
       "  2119,\n",
       "  1282,\n",
       "  1282,\n",
       "  1312,\n",
       "  1449,\n",
       "  1580,\n",
       "  1680,\n",
       "  1778,\n",
       "  1281,\n",
       "  1281,\n",
       "  1282,\n",
       "  1282,\n",
       "  1387,\n",
       "  1437,\n",
       "  1508,\n",
       "  1659,\n",
       "  1734,\n",
       "  1810,\n",
       "  1880,\n",
       "  2153,\n",
       "  1281,\n",
       "  1281,\n",
       "  1353,\n",
       "  1440,\n",
       "  1634,\n",
       "  1686,\n",
       "  1757,\n",
       "  1866,\n",
       "  1917,\n",
       "  1988,\n",
       "  1282,\n",
       "  1282,\n",
       "  1455,\n",
       "  1545,\n",
       "  1612,\n",
       "  1714,\n",
       "  1815,\n",
       "  1281,\n",
       "  1281,\n",
       "  1327,\n",
       "  1327,\n",
       "  1384,\n",
       "  1501,\n",
       "  1566,\n",
       "  1775,\n",
       "  1963,\n",
       "  2026,\n",
       "  2135,\n",
       "  1281,\n",
       "  1281,\n",
       "  1546,\n",
       "  1730,\n",
       "  1795,\n",
       "  1995,\n",
       "  2070,\n",
       "  1281,\n",
       "  1281,\n",
       "  1383,\n",
       "  1484,\n",
       "  1563,\n",
       "  1614,\n",
       "  1720,\n",
       "  1842,\n",
       "  1992,\n",
       "  1282,\n",
       "  1282,\n",
       "  1365,\n",
       "  1585,\n",
       "  1642,\n",
       "  1783,\n",
       "  1912,\n",
       "  2120,\n",
       "  1281,\n",
       "  1281,\n",
       "  1462,\n",
       "  1532,\n",
       "  1632,\n",
       "  1684,\n",
       "  1793,\n",
       "  1845,\n",
       "  1879,\n",
       "  2069,\n",
       "  1281,\n",
       "  1281,\n",
       "  1375,\n",
       "  1568,\n",
       "  1892,\n",
       "  2074,\n",
       "  1281,\n",
       "  1281,\n",
       "  1348,\n",
       "  1597,\n",
       "  1281,\n",
       "  1281,\n",
       "  1327,\n",
       "  1327,\n",
       "  1476,\n",
       "  1545,\n",
       "  1734,\n",
       "  1784,\n",
       "  1899,\n",
       "  1956,\n",
       "  1281,\n",
       "  1281,\n",
       "  1456,\n",
       "  1714,\n",
       "  1806,\n",
       "  2084,\n",
       "  1282,\n",
       "  1282,\n",
       "  1369,\n",
       "  1449,\n",
       "  1532,\n",
       "  1747,\n",
       "  1893,\n",
       "  2135,\n",
       "  1281,\n",
       "  1281,\n",
       "  1390,\n",
       "  1674,\n",
       "  1772,\n",
       "  1836,\n",
       "  1903,\n",
       "  1987,\n",
       "  2120,\n",
       "  1282,\n",
       "  1282,\n",
       "  1350,\n",
       "  1402,\n",
       "  1472,\n",
       "  1687,\n",
       "  1939,\n",
       "  2064,\n",
       "  2110,\n",
       "  1282,\n",
       "  1282,\n",
       "  1353,\n",
       "  1416,\n",
       "  1556,\n",
       "  1770,\n",
       "  1841,\n",
       "  1959,\n",
       "  2110,\n",
       "  1282,\n",
       "  1282,\n",
       "  1533,\n",
       "  1613,\n",
       "  1739,\n",
       "  1782,\n",
       "  1949,\n",
       "  2014,\n",
       "  2108,\n",
       "  1281,\n",
       "  1281,\n",
       "  1410,\n",
       "  1486,\n",
       "  1743,\n",
       "  1281,\n",
       "  1281,\n",
       "  1281,\n",
       "  1281,\n",
       "  1357,\n",
       "  1281,\n",
       "  1281,\n",
       "  1281,\n",
       "  1281,\n",
       "  1430,\n",
       "  1624,\n",
       "  1906,\n",
       "  1994,\n",
       "  2052,\n",
       "  1282,\n",
       "  1282,\n",
       "  1442,\n",
       "  1533,\n",
       "  1708,\n",
       "  1850,\n",
       "  1946,\n",
       "  1281,\n",
       "  1281,\n",
       "  1364,\n",
       "  1463,\n",
       "  1718,\n",
       "  1948,\n",
       "  1995,\n",
       "  2052,\n",
       "  1281,\n",
       "  1281,\n",
       "  1365,\n",
       "  1416,\n",
       "  1530,\n",
       "  1707,\n",
       "  1979,\n",
       "  2153,\n",
       "  1281,\n",
       "  1281,\n",
       "  1480,\n",
       "  1588,\n",
       "  1723,\n",
       "  1856,\n",
       "  1955,\n",
       "  1281,\n",
       "  1281,\n",
       "  1384,\n",
       "  1431,\n",
       "  1568,\n",
       "  1669,\n",
       "  1767,\n",
       "  2033,\n",
       "  1281,\n",
       "  1281,\n",
       "  1410,\n",
       "  1496,\n",
       "  1619,\n",
       "  1855,\n",
       "  1902,\n",
       "  2042,\n",
       "  1281,\n",
       "  1281,\n",
       "  1383,\n",
       "  1488,\n",
       "  1644,\n",
       "  1691,\n",
       "  1788,\n",
       "  2033,\n",
       "  1281,\n",
       "  1281,\n",
       "  1393,\n",
       "  1561,\n",
       "  1630,\n",
       "  1732,\n",
       "  1943,\n",
       "  2068,\n",
       "  2116,\n",
       "  1282,\n",
       "  1282,\n",
       "  1454,\n",
       "  1575,\n",
       "  1605,\n",
       "  1722,\n",
       "  1783,\n",
       "  1831,\n",
       "  1929],\n",
       " 'top': [0,\n",
       "  276,\n",
       "  276,\n",
       "  276,\n",
       "  276,\n",
       "  276,\n",
       "  286,\n",
       "  276,\n",
       "  276,\n",
       "  276,\n",
       "  276,\n",
       "  276,\n",
       "  333,\n",
       "  333,\n",
       "  333,\n",
       "  333,\n",
       "  333,\n",
       "  333,\n",
       "  333,\n",
       "  338,\n",
       "  389,\n",
       "  394,\n",
       "  389,\n",
       "  389,\n",
       "  389,\n",
       "  389,\n",
       "  394,\n",
       "  389,\n",
       "  389,\n",
       "  399,\n",
       "  446,\n",
       "  446,\n",
       "  446,\n",
       "  446,\n",
       "  446,\n",
       "  446,\n",
       "  446,\n",
       "  446,\n",
       "  502,\n",
       "  502,\n",
       "  502,\n",
       "  502,\n",
       "  502,\n",
       "  507,\n",
       "  502,\n",
       "  502,\n",
       "  502,\n",
       "  502,\n",
       "  559,\n",
       "  559,\n",
       "  564,\n",
       "  559,\n",
       "  559,\n",
       "  564,\n",
       "  559,\n",
       "  559,\n",
       "  559,\n",
       "  615,\n",
       "  620,\n",
       "  615,\n",
       "  615,\n",
       "  615,\n",
       "  615,\n",
       "  615,\n",
       "  615,\n",
       "  625,\n",
       "  615,\n",
       "  672,\n",
       "  672,\n",
       "  672,\n",
       "  692,\n",
       "  682,\n",
       "  672,\n",
       "  672,\n",
       "  672,\n",
       "  672,\n",
       "  728,\n",
       "  728,\n",
       "  728,\n",
       "  728,\n",
       "  728,\n",
       "  738,\n",
       "  728,\n",
       "  728,\n",
       "  784,\n",
       "  784,\n",
       "  784,\n",
       "  794,\n",
       "  784,\n",
       "  794,\n",
       "  794,\n",
       "  784,\n",
       "  784,\n",
       "  784,\n",
       "  794,\n",
       "  841,\n",
       "  841,\n",
       "  841,\n",
       "  841,\n",
       "  846,\n",
       "  841,\n",
       "  841,\n",
       "  897,\n",
       "  897,\n",
       "  897,\n",
       "  907,\n",
       "  897,\n",
       "  897,\n",
       "  897,\n",
       "  897,\n",
       "  907,\n",
       "  954,\n",
       "  954,\n",
       "  954,\n",
       "  954,\n",
       "  964,\n",
       "  954,\n",
       "  1010,\n",
       "  1010,\n",
       "  1010,\n",
       "  1010,\n",
       "  1010,\n",
       "  1020,\n",
       "  1010,\n",
       "  1114,\n",
       "  1114,\n",
       "  1114,\n",
       "  1114,\n",
       "  1114,\n",
       "  1114,\n",
       "  1114,\n",
       "  1114,\n",
       "  1193,\n",
       "  1193,\n",
       "  1193,\n",
       "  1193,\n",
       "  1193,\n",
       "  1193,\n",
       "  1194,\n",
       "  1193,\n",
       "  1193,\n",
       "  1203,\n",
       "  1193,\n",
       "  1193,\n",
       "  1193,\n",
       "  1250,\n",
       "  1250,\n",
       "  1250,\n",
       "  1250,\n",
       "  1250,\n",
       "  1260,\n",
       "  1250,\n",
       "  1250,\n",
       "  1306,\n",
       "  1306,\n",
       "  1306,\n",
       "  1306,\n",
       "  1306,\n",
       "  1311,\n",
       "  1306,\n",
       "  1306,\n",
       "  1306,\n",
       "  1306,\n",
       "  1363,\n",
       "  1363,\n",
       "  1368,\n",
       "  1373,\n",
       "  1363,\n",
       "  1363,\n",
       "  1373,\n",
       "  1373,\n",
       "  1363,\n",
       "  1419,\n",
       "  1424,\n",
       "  1419,\n",
       "  1420,\n",
       "  1419,\n",
       "  1419,\n",
       "  1419,\n",
       "  1476,\n",
       "  1476,\n",
       "  1476,\n",
       "  1476,\n",
       "  1486,\n",
       "  1476,\n",
       "  1476,\n",
       "  1476,\n",
       "  1486,\n",
       "  1532,\n",
       "  1532,\n",
       "  1532,\n",
       "  1532,\n",
       "  1532,\n",
       "  1532,\n",
       "  1532,\n",
       "  1537,\n",
       "  1588,\n",
       "  1588,\n",
       "  1588,\n",
       "  1598,\n",
       "  1588,\n",
       "  1588,\n",
       "  1588,\n",
       "  1588,\n",
       "  1598,\n",
       "  1589,\n",
       "  1645,\n",
       "  1645,\n",
       "  1645,\n",
       "  1645,\n",
       "  1645,\n",
       "  1645,\n",
       "  1645,\n",
       "  1701,\n",
       "  1711,\n",
       "  1701,\n",
       "  1701,\n",
       "  1701,\n",
       "  1706,\n",
       "  1701,\n",
       "  1701,\n",
       "  1758,\n",
       "  1758,\n",
       "  1758,\n",
       "  1768,\n",
       "  1758,\n",
       "  1758,\n",
       "  1758,\n",
       "  1814,\n",
       "  1819,\n",
       "  1819,\n",
       "  1824,\n",
       "  1814,\n",
       "  1814,\n",
       "  1814,\n",
       "  1814,\n",
       "  1871,\n",
       "  1871,\n",
       "  1871,\n",
       "  1881,\n",
       "  1871,\n",
       "  1871,\n",
       "  1881,\n",
       "  1881,\n",
       "  1871,\n",
       "  1927,\n",
       "  1927,\n",
       "  1927,\n",
       "  1927,\n",
       "  1937,\n",
       "  1932,\n",
       "  1927,\n",
       "  1927,\n",
       "  1927,\n",
       "  1987,\n",
       "  1987,\n",
       "  1988,\n",
       "  1987,\n",
       "  1987,\n",
       "  1997,\n",
       "  1997,\n",
       "  1987,\n",
       "  1992,\n",
       "  1987,\n",
       "  2043,\n",
       "  2043,\n",
       "  2043,\n",
       "  2044,\n",
       "  2048,\n",
       "  2043,\n",
       "  2043,\n",
       "  2043,\n",
       "  2100,\n",
       "  2100,\n",
       "  2100,\n",
       "  2101,\n",
       "  2100,\n",
       "  2100,\n",
       "  2100,\n",
       "  2100,\n",
       "  2156,\n",
       "  2156,\n",
       "  2157,\n",
       "  2156,\n",
       "  2156,\n",
       "  2157,\n",
       "  2156,\n",
       "  2156,\n",
       "  2161,\n",
       "  2157,\n",
       "  2166,\n",
       "  2213,\n",
       "  2223,\n",
       "  2223,\n",
       "  2213,\n",
       "  2213,\n",
       "  2213,\n",
       "  2213,\n",
       "  2223,\n",
       "  2269,\n",
       "  2269,\n",
       "  2269,\n",
       "  2269,\n",
       "  2269,\n",
       "  2274,\n",
       "  2269,\n",
       "  2325,\n",
       "  2325,\n",
       "  2325,\n",
       "  2325,\n",
       "  2325,\n",
       "  2325,\n",
       "  2325,\n",
       "  2335,\n",
       "  2325,\n",
       "  2382,\n",
       "  2382,\n",
       "  2382,\n",
       "  2392,\n",
       "  2392,\n",
       "  2382,\n",
       "  2382,\n",
       "  2382,\n",
       "  2382,\n",
       "  2387,\n",
       "  2392,\n",
       "  2392,\n",
       "  2382,\n",
       "  2532,\n",
       "  2532,\n",
       "  2532,\n",
       "  2532,\n",
       "  2597,\n",
       "  2597,\n",
       "  2597,\n",
       "  2597,\n",
       "  2597,\n",
       "  2597,\n",
       "  2597,\n",
       "  2597,\n",
       "  2597,\n",
       "  2660,\n",
       "  2660,\n",
       "  2660,\n",
       "  2661,\n",
       "  2660,\n",
       "  2661,\n",
       "  2661,\n",
       "  2661,\n",
       "  2661,\n",
       "  2661,\n",
       "  2702,\n",
       "  2702,\n",
       "  2702,\n",
       "  2703,\n",
       "  2703,\n",
       "  2703,\n",
       "  2703,\n",
       "  2703,\n",
       "  2743,\n",
       "  2743,\n",
       "  2743,\n",
       "  2744,\n",
       "  2743,\n",
       "  2744,\n",
       "  2744,\n",
       "  2744,\n",
       "  2785,\n",
       "  2786,\n",
       "  2785,\n",
       "  2786,\n",
       "  2786,\n",
       "  2786,\n",
       "  2785,\n",
       "  2786,\n",
       "  2826,\n",
       "  2827,\n",
       "  2827,\n",
       "  2826,\n",
       "  2827,\n",
       "  2827,\n",
       "  2826,\n",
       "  2827,\n",
       "  2868,\n",
       "  2869,\n",
       "  2869,\n",
       "  2868,\n",
       "  2869,\n",
       "  2869,\n",
       "  2869,\n",
       "  2869,\n",
       "  2532,\n",
       "  2532,\n",
       "  2532,\n",
       "  2532,\n",
       "  2532,\n",
       "  2532,\n",
       "  2578,\n",
       "  2578,\n",
       "  2578,\n",
       "  2578,\n",
       "  2642,\n",
       "  2642,\n",
       "  2642,\n",
       "  2642,\n",
       "  2987,\n",
       "  2987,\n",
       "  2987,\n",
       "  2987,\n",
       "  2987,\n",
       "  2987,\n",
       "  2996,\n",
       "  2987,\n",
       "  2987,\n",
       "  2987,\n",
       "  2987,\n",
       "  2999,\n",
       "  2987,\n",
       "  3036,\n",
       "  3036,\n",
       "  3036,\n",
       "  3036,\n",
       "  3036,\n",
       "  3048,\n",
       "  3036,\n",
       "  3036,\n",
       "  3036,\n",
       "  3048,\n",
       "  3036,\n",
       "  3036,\n",
       "  3041,\n",
       "  3086,\n",
       "  3086,\n",
       "  3086,\n",
       "  3086,\n",
       "  3086,\n",
       "  3086,\n",
       "  3086,\n",
       "  3086,\n",
       "  3086,\n",
       "  3086,\n",
       "  3136,\n",
       "  3136,\n",
       "  3136,\n",
       "  3136,\n",
       "  3136,\n",
       "  475,\n",
       "  475,\n",
       "  475,\n",
       "  475,\n",
       "  622,\n",
       "  622,\n",
       "  622,\n",
       "  622,\n",
       "  282,\n",
       "  282,\n",
       "  282,\n",
       "  282,\n",
       "  282,\n",
       "  282,\n",
       "  282,\n",
       "  282,\n",
       "  346,\n",
       "  346,\n",
       "  346,\n",
       "  350,\n",
       "  346,\n",
       "  346,\n",
       "  346,\n",
       "  346,\n",
       "  388,\n",
       "  388,\n",
       "  388,\n",
       "  392,\n",
       "  388,\n",
       "  388,\n",
       "  403,\n",
       "  388,\n",
       "  428,\n",
       "  429,\n",
       "  429,\n",
       "  433,\n",
       "  429,\n",
       "  429,\n",
       "  444,\n",
       "  428,\n",
       "  493,\n",
       "  493,\n",
       "  494,\n",
       "  531,\n",
       "  531,\n",
       "  531,\n",
       "  547,\n",
       "  534,\n",
       "  535,\n",
       "  572,\n",
       "  572,\n",
       "  577,\n",
       "  572,\n",
       "  576,\n",
       "  577,\n",
       "  641,\n",
       "  641,\n",
       "  641,\n",
       "  641,\n",
       "  678,\n",
       "  678,\n",
       "  678,\n",
       "  683,\n",
       "  698,\n",
       "  723,\n",
       "  723,\n",
       "  724,\n",
       "  723,\n",
       "  723,\n",
       "  739,\n",
       "  765,\n",
       "  765,\n",
       "  766,\n",
       "  765,\n",
       "  766,\n",
       "  781,\n",
       "  806,\n",
       "  806,\n",
       "  806,\n",
       "  807,\n",
       "  807,\n",
       "  807,\n",
       "  807,\n",
       "  806,\n",
       "  807,\n",
       "  822,\n",
       "  848,\n",
       "  849,\n",
       "  849,\n",
       "  849,\n",
       "  849,\n",
       "  848,\n",
       "  864,\n",
       "  890,\n",
       "  890,\n",
       "  890,\n",
       "  890,\n",
       "  890,\n",
       "  890,\n",
       "  890,\n",
       "  905,\n",
       "  988,\n",
       "  988,\n",
       "  988,\n",
       "  988,\n",
       "  988,\n",
       "  988,\n",
       "  988,\n",
       "  988,\n",
       "  988,\n",
       "  997,\n",
       "  1037,\n",
       "  1037,\n",
       "  1037,\n",
       "  1046,\n",
       "  1037,\n",
       "  1037,\n",
       "  1037,\n",
       "  1037,\n",
       "  1087,\n",
       "  1092,\n",
       "  1087,\n",
       "  1087,\n",
       "  1087,\n",
       "  1087,\n",
       "  1087,\n",
       "  1096,\n",
       "  1096,\n",
       "  1087,\n",
       "  1096,\n",
       "  1137,\n",
       "  1137,\n",
       "  1137,\n",
       "  1142,\n",
       "  1137,\n",
       "  1137,\n",
       "  1137,\n",
       "  1310,\n",
       "  1310,\n",
       "  1310,\n",
       "  1310,\n",
       "  1310,\n",
       "  1310,\n",
       "  1315,\n",
       "  1311,\n",
       "  1320,\n",
       "  1310,\n",
       "  1310,\n",
       "  1310,\n",
       "  1366,\n",
       "  1366,\n",
       "  1366,\n",
       "  1366,\n",
       "  1376,\n",
       "  1366,\n",
       "  1366,\n",
       "  1371,\n",
       "  1366,\n",
       "  1366,\n",
       "  1423,\n",
       "  1423,\n",
       "  1433,\n",
       "  1423,\n",
       "  1424,\n",
       "  1423,\n",
       "  1428,\n",
       "  1495,\n",
       "  1495,\n",
       "  1495,\n",
       "  1496,\n",
       "  1495,\n",
       "  1495,\n",
       "  1495,\n",
       "  1495,\n",
       "  1505,\n",
       "  1495,\n",
       "  1495,\n",
       "  1552,\n",
       "  1552,\n",
       "  1552,\n",
       "  1552,\n",
       "  1552,\n",
       "  1552,\n",
       "  1552,\n",
       "  1608,\n",
       "  1608,\n",
       "  1608,\n",
       "  1618,\n",
       "  1618,\n",
       "  1618,\n",
       "  1608,\n",
       "  1608,\n",
       "  1608,\n",
       "  1665,\n",
       "  1675,\n",
       "  1670,\n",
       "  1665,\n",
       "  1666,\n",
       "  1665,\n",
       "  1665,\n",
       "  1675,\n",
       "  1721,\n",
       "  1721,\n",
       "  1731,\n",
       "  1721,\n",
       "  1731,\n",
       "  1721,\n",
       "  1726,\n",
       "  1731,\n",
       "  1721,\n",
       "  1721,\n",
       "  1778,\n",
       "  1778,\n",
       "  1778,\n",
       "  1778,\n",
       "  1778,\n",
       "  1778,\n",
       "  1834,\n",
       "  1834,\n",
       "  1834,\n",
       "  1834,\n",
       "  1907,\n",
       "  1907,\n",
       "  1907,\n",
       "  1907,\n",
       "  1917,\n",
       "  1907,\n",
       "  1907,\n",
       "  1907,\n",
       "  1908,\n",
       "  1908,\n",
       "  1963,\n",
       "  1963,\n",
       "  1963,\n",
       "  1963,\n",
       "  1963,\n",
       "  1963,\n",
       "  2019,\n",
       "  2019,\n",
       "  2019,\n",
       "  2019,\n",
       "  2019,\n",
       "  2019,\n",
       "  2024,\n",
       "  2019,\n",
       "  2076,\n",
       "  2076,\n",
       "  2076,\n",
       "  2076,\n",
       "  2076,\n",
       "  2081,\n",
       "  2076,\n",
       "  2076,\n",
       "  2076,\n",
       "  2132,\n",
       "  2142,\n",
       "  2132,\n",
       "  2132,\n",
       "  2132,\n",
       "  2132,\n",
       "  2132,\n",
       "  2132,\n",
       "  2132,\n",
       "  2189,\n",
       "  2189,\n",
       "  2189,\n",
       "  2189,\n",
       "  2189,\n",
       "  2189,\n",
       "  2189,\n",
       "  2189,\n",
       "  2189,\n",
       "  2245,\n",
       "  2245,\n",
       "  2245,\n",
       "  2246,\n",
       "  2245,\n",
       "  2245,\n",
       "  2245,\n",
       "  2245,\n",
       "  2245,\n",
       "  2302,\n",
       "  2302,\n",
       "  2302,\n",
       "  2302,\n",
       "  2302,\n",
       "  2453,\n",
       "  2453,\n",
       "  2453,\n",
       "  2453,\n",
       "  2453,\n",
       "  2583,\n",
       "  2583,\n",
       "  2583,\n",
       "  2584,\n",
       "  2583,\n",
       "  2583,\n",
       "  2583,\n",
       "  2588,\n",
       "  2583,\n",
       "  2640,\n",
       "  2640,\n",
       "  2640,\n",
       "  2640,\n",
       "  2640,\n",
       "  2640,\n",
       "  2640,\n",
       "  2696,\n",
       "  2696,\n",
       "  2696,\n",
       "  2696,\n",
       "  2696,\n",
       "  2696,\n",
       "  2706,\n",
       "  2696,\n",
       "  2753,\n",
       "  2758,\n",
       "  2753,\n",
       "  2763,\n",
       "  2753,\n",
       "  2753,\n",
       "  2758,\n",
       "  2754,\n",
       "  2809,\n",
       "  2809,\n",
       "  2809,\n",
       "  2809,\n",
       "  2809,\n",
       "  2819,\n",
       "  2809,\n",
       "  2866,\n",
       "  2866,\n",
       "  2871,\n",
       "  2866,\n",
       "  2866,\n",
       "  2866,\n",
       "  2866,\n",
       "  2866,\n",
       "  2922,\n",
       "  2927,\n",
       "  2922,\n",
       "  2922,\n",
       "  2922,\n",
       "  2922,\n",
       "  2922,\n",
       "  2922,\n",
       "  2979,\n",
       "  2979,\n",
       "  2979,\n",
       "  2979,\n",
       "  2984,\n",
       "  2979,\n",
       "  2979,\n",
       "  2979,\n",
       "  3035,\n",
       "  3040,\n",
       "  3035,\n",
       "  3035,\n",
       "  3045,\n",
       "  3035,\n",
       "  3035,\n",
       "  3040,\n",
       "  3045,\n",
       "  3092,\n",
       "  3092,\n",
       "  3092,\n",
       "  3102,\n",
       "  3092,\n",
       "  3097,\n",
       "  3092,\n",
       "  3093,\n",
       "  3092],\n",
       " 'width': [2481,\n",
       "  912,\n",
       "  912,\n",
       "  911,\n",
       "  111,\n",
       "  117,\n",
       "  44,\n",
       "  53,\n",
       "  220,\n",
       "  72,\n",
       "  123,\n",
       "  39,\n",
       "  907,\n",
       "  184,\n",
       "  53,\n",
       "  199,\n",
       "  117,\n",
       "  67,\n",
       "  87,\n",
       "  66,\n",
       "  907,\n",
       "  33,\n",
       "  75,\n",
       "  105,\n",
       "  63,\n",
       "  173,\n",
       "  31,\n",
       "  39,\n",
       "  117,\n",
       "  91,\n",
       "  907,\n",
       "  112,\n",
       "  33,\n",
       "  135,\n",
       "  67,\n",
       "  185,\n",
       "  122,\n",
       "  126,\n",
       "  906,\n",
       "  73,\n",
       "  67,\n",
       "  87,\n",
       "  66,\n",
       "  34,\n",
       "  66,\n",
       "  129,\n",
       "  57,\n",
       "  185,\n",
       "  907,\n",
       "  123,\n",
       "  34,\n",
       "  96,\n",
       "  56,\n",
       "  57,\n",
       "  94,\n",
       "  123,\n",
       "  163,\n",
       "  907,\n",
       "  116,\n",
       "  87,\n",
       "  39,\n",
       "  91,\n",
       "  89,\n",
       "  108,\n",
       "  82,\n",
       "  19,\n",
       "  139,\n",
       "  908,\n",
       "  103,\n",
       "  164,\n",
       "  46,\n",
       "  51,\n",
       "  215,\n",
       "  67,\n",
       "  96,\n",
       "  53,\n",
       "  908,\n",
       "  112,\n",
       "  28,\n",
       "  183,\n",
       "  136,\n",
       "  43,\n",
       "  53,\n",
       "  219,\n",
       "  907,\n",
       "  88,\n",
       "  63,\n",
       "  75,\n",
       "  79,\n",
       "  18,\n",
       "  77,\n",
       "  95,\n",
       "  138,\n",
       "  38,\n",
       "  71,\n",
       "  907,\n",
       "  114,\n",
       "  180,\n",
       "  180,\n",
       "  207,\n",
       "  54,\n",
       "  86,\n",
       "  906,\n",
       "  135,\n",
       "  128,\n",
       "  61,\n",
       "  123,\n",
       "  87,\n",
       "  54,\n",
       "  110,\n",
       "  91,\n",
       "  907,\n",
       "  187,\n",
       "  199,\n",
       "  273,\n",
       "  82,\n",
       "  96,\n",
       "  643,\n",
       "  220,\n",
       "  73,\n",
       "  75,\n",
       "  27,\n",
       "  77,\n",
       "  105,\n",
       "  810,\n",
       "  810,\n",
       "  810,\n",
       "  54,\n",
       "  274,\n",
       "  191,\n",
       "  83,\n",
       "  120,\n",
       "  909,\n",
       "  908,\n",
       "  908,\n",
       "  56,\n",
       "  38,\n",
       "  53,\n",
       "  112,\n",
       "  116,\n",
       "  173,\n",
       "  36,\n",
       "  49,\n",
       "  82,\n",
       "  82,\n",
       "  907,\n",
       "  53,\n",
       "  197,\n",
       "  174,\n",
       "  108,\n",
       "  19,\n",
       "  118,\n",
       "  139,\n",
       "  908,\n",
       "  109,\n",
       "  90,\n",
       "  27,\n",
       "  106,\n",
       "  34,\n",
       "  53,\n",
       "  198,\n",
       "  121,\n",
       "  63,\n",
       "  906,\n",
       "  43,\n",
       "  197,\n",
       "  53,\n",
       "  120,\n",
       "  183,\n",
       "  43,\n",
       "  19,\n",
       "  112,\n",
       "  905,\n",
       "  119,\n",
       "  80,\n",
       "  169,\n",
       "  53,\n",
       "  243,\n",
       "  174,\n",
       "  907,\n",
       "  109,\n",
       "  89,\n",
       "  141,\n",
       "  52,\n",
       "  164,\n",
       "  88,\n",
       "  54,\n",
       "  71,\n",
       "  908,\n",
       "  125,\n",
       "  121,\n",
       "  58,\n",
       "  121,\n",
       "  207,\n",
       "  92,\n",
       "  57,\n",
       "  906,\n",
       "  43,\n",
       "  89,\n",
       "  61,\n",
       "  41,\n",
       "  103,\n",
       "  209,\n",
       "  44,\n",
       "  18,\n",
       "  115,\n",
       "  907,\n",
       "  123,\n",
       "  143,\n",
       "  222,\n",
       "  63,\n",
       "  162,\n",
       "  127,\n",
       "  904,\n",
       "  18,\n",
       "  225,\n",
       "  112,\n",
       "  211,\n",
       "  33,\n",
       "  41,\n",
       "  115,\n",
       "  906,\n",
       "  141,\n",
       "  89,\n",
       "  53,\n",
       "  105,\n",
       "  258,\n",
       "  140,\n",
       "  907,\n",
       "  33,\n",
       "  229,\n",
       "  40,\n",
       "  176,\n",
       "  256,\n",
       "  39,\n",
       "  53,\n",
       "  907,\n",
       "  139,\n",
       "  75,\n",
       "  83,\n",
       "  63,\n",
       "  77,\n",
       "  60,\n",
       "  98,\n",
       "  219,\n",
       "  905,\n",
       "  79,\n",
       "  141,\n",
       "  128,\n",
       "  43,\n",
       "  56,\n",
       "  39,\n",
       "  63,\n",
       "  266,\n",
       "  909,\n",
       "  862,\n",
       "  36,\n",
       "  63,\n",
       "  135,\n",
       "  50,\n",
       "  154,\n",
       "  53,\n",
       "  66,\n",
       "  201,\n",
       "  909,\n",
       "  44,\n",
       "  155,\n",
       "  112,\n",
       "  33,\n",
       "  54,\n",
       "  243,\n",
       "  130,\n",
       "  907,\n",
       "  109,\n",
       "  221,\n",
       "  117,\n",
       "  73,\n",
       "  120,\n",
       "  79,\n",
       "  88,\n",
       "  906,\n",
       "  63,\n",
       "  51,\n",
       "  162,\n",
       "  113,\n",
       "  36,\n",
       "  53,\n",
       "  92,\n",
       "  34,\n",
       "  118,\n",
       "  50,\n",
       "  907,\n",
       "  58,\n",
       "  19,\n",
       "  283,\n",
       "  197,\n",
       "  121,\n",
       "  63,\n",
       "  50,\n",
       "  908,\n",
       "  131,\n",
       "  53,\n",
       "  158,\n",
       "  178,\n",
       "  132,\n",
       "  160,\n",
       "  908,\n",
       "  44,\n",
       "  54,\n",
       "  83,\n",
       "  183,\n",
       "  151,\n",
       "  152,\n",
       "  51,\n",
       "  65,\n",
       "  908,\n",
       "  121,\n",
       "  63,\n",
       "  34,\n",
       "  19,\n",
       "  134,\n",
       "  73,\n",
       "  57,\n",
       "  43,\n",
       "  57,\n",
       "  58,\n",
       "  7,\n",
       "  84,\n",
       "  795,\n",
       "  795,\n",
       "  199,\n",
       "  199,\n",
       "  795,\n",
       "  40,\n",
       "  44,\n",
       "  44,\n",
       "  54,\n",
       "  70,\n",
       "  136,\n",
       "  101,\n",
       "  89,\n",
       "  777,\n",
       "  777,\n",
       "  758,\n",
       "  15,\n",
       "  53,\n",
       "  32,\n",
       "  63,\n",
       "  63,\n",
       "  62,\n",
       "  63,\n",
       "  757,\n",
       "  16,\n",
       "  53,\n",
       "  15,\n",
       "  63,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  756,\n",
       "  16,\n",
       "  53,\n",
       "  32,\n",
       "  63,\n",
       "  61,\n",
       "  61,\n",
       "  62,\n",
       "  773,\n",
       "  32,\n",
       "  53,\n",
       "  32,\n",
       "  63,\n",
       "  62,\n",
       "  61,\n",
       "  63,\n",
       "  772,\n",
       "  32,\n",
       "  69,\n",
       "  32,\n",
       "  63,\n",
       "  61,\n",
       "  62,\n",
       "  62,\n",
       "  776,\n",
       "  35,\n",
       "  69,\n",
       "  32,\n",
       "  62,\n",
       "  61,\n",
       "  61,\n",
       "  63,\n",
       "  269,\n",
       "  269,\n",
       "  269,\n",
       "  60,\n",
       "  46,\n",
       "  141,\n",
       "  797,\n",
       "  797,\n",
       "  797,\n",
       "  797,\n",
       "  797,\n",
       "  797,\n",
       "  797,\n",
       "  797,\n",
       "  907,\n",
       "  907,\n",
       "  907,\n",
       "  89,\n",
       "  27,\n",
       "  144,\n",
       "  71,\n",
       "  102,\n",
       "  102,\n",
       "  70,\n",
       "  45,\n",
       "  21,\n",
       "  49,\n",
       "  906,\n",
       "  126,\n",
       "  35,\n",
       "  107,\n",
       "  50,\n",
       "  21,\n",
       "  111,\n",
       "  72,\n",
       "  50,\n",
       "  21,\n",
       "  126,\n",
       "  35,\n",
       "  40,\n",
       "  907,\n",
       "  113,\n",
       "  101,\n",
       "  78,\n",
       "  96,\n",
       "  25,\n",
       "  49,\n",
       "  125,\n",
       "  61,\n",
       "  166,\n",
       "  409,\n",
       "  36,\n",
       "  137,\n",
       "  127,\n",
       "  76,\n",
       "  828,\n",
       "  828,\n",
       "  828,\n",
       "  828,\n",
       "  828,\n",
       "  828,\n",
       "  828,\n",
       "  828,\n",
       "  823,\n",
       "  823,\n",
       "  822,\n",
       "  108,\n",
       "  60,\n",
       "  34,\n",
       "  61,\n",
       "  35,\n",
       "  804,\n",
       "  96,\n",
       "  100,\n",
       "  26,\n",
       "  43,\n",
       "  101,\n",
       "  62,\n",
       "  64,\n",
       "  803,\n",
       "  73,\n",
       "  93,\n",
       "  26,\n",
       "  43,\n",
       "  85,\n",
       "  10,\n",
       "  63,\n",
       "  803,\n",
       "  67,\n",
       "  104,\n",
       "  26,\n",
       "  43,\n",
       "  85,\n",
       "  10,\n",
       "  63,\n",
       "  319,\n",
       "  172,\n",
       "  135,\n",
       "  772,\n",
       "  772,\n",
       "  83,\n",
       "  86,\n",
       "  63,\n",
       "  62,\n",
       "  804,\n",
       "  773,\n",
       "  83,\n",
       "  67,\n",
       "  63,\n",
       "  63,\n",
       "  550,\n",
       "  208,\n",
       "  135,\n",
       "  184,\n",
       "  745,\n",
       "  745,\n",
       "  185,\n",
       "  63,\n",
       "  9,\n",
       "  744,\n",
       "  744,\n",
       "  226,\n",
       "  109,\n",
       "  63,\n",
       "  9,\n",
       "  745,\n",
       "  745,\n",
       "  63,\n",
       "  109,\n",
       "  63,\n",
       "  9,\n",
       "  746,\n",
       "  746,\n",
       "  746,\n",
       "  142,\n",
       "  67,\n",
       "  64,\n",
       "  69,\n",
       "  109,\n",
       "  63,\n",
       "  9,\n",
       "  745,\n",
       "  105,\n",
       "  63,\n",
       "  69,\n",
       "  108,\n",
       "  60,\n",
       "  9,\n",
       "  746,\n",
       "  142,\n",
       "  67,\n",
       "  46,\n",
       "  32,\n",
       "  100,\n",
       "  62,\n",
       "  9,\n",
       "  909,\n",
       "  909,\n",
       "  907,\n",
       "  89,\n",
       "  27,\n",
       "  222,\n",
       "  118,\n",
       "  100,\n",
       "  201,\n",
       "  44,\n",
       "  906,\n",
       "  81,\n",
       "  283,\n",
       "  78,\n",
       "  130,\n",
       "  87,\n",
       "  49,\n",
       "  67,\n",
       "  907,\n",
       "  51,\n",
       "  62,\n",
       "  137,\n",
       "  66,\n",
       "  58,\n",
       "  67,\n",
       "  100,\n",
       "  48,\n",
       "  146,\n",
       "  71,\n",
       "  779,\n",
       "  16,\n",
       "  126,\n",
       "  118,\n",
       "  87,\n",
       "  86,\n",
       "  283,\n",
       "  911,\n",
       "  911,\n",
       "  910,\n",
       "  89,\n",
       "  33,\n",
       "  53,\n",
       "  123,\n",
       "  58,\n",
       "  59,\n",
       "  53,\n",
       "  256,\n",
       "  39,\n",
       "  908,\n",
       "  53,\n",
       "  69,\n",
       "  176,\n",
       "  34,\n",
       "  54,\n",
       "  93,\n",
       "  33,\n",
       "  54,\n",
       "  201,\n",
       "  590,\n",
       "  160,\n",
       "  78,\n",
       "  53,\n",
       "  89,\n",
       "  87,\n",
       "  57,\n",
       "  907,\n",
       "  907,\n",
       "  861,\n",
       "  44,\n",
       "  105,\n",
       "  53,\n",
       "  197,\n",
       "  174,\n",
       "  50,\n",
       "  97,\n",
       "  53,\n",
       "  907,\n",
       "  244,\n",
       "  164,\n",
       "  44,\n",
       "  179,\n",
       "  53,\n",
       "  118,\n",
       "  907,\n",
       "  86,\n",
       "  87,\n",
       "  63,\n",
       "  37,\n",
       "  91,\n",
       "  106,\n",
       "  136,\n",
       "  196,\n",
       "  906,\n",
       "  62,\n",
       "  197,\n",
       "  39,\n",
       "  118,\n",
       "  107,\n",
       "  187,\n",
       "  68,\n",
       "  907,\n",
       "  162,\n",
       "  52,\n",
       "  82,\n",
       "  34,\n",
       "  92,\n",
       "  33,\n",
       "  18,\n",
       "  173,\n",
       "  119,\n",
       "  907,\n",
       "  75,\n",
       "  173,\n",
       "  304,\n",
       "  162,\n",
       "  114,\n",
       "  412,\n",
       "  53,\n",
       "  236,\n",
       "  96,\n",
       "  907,\n",
       "  907,\n",
       "  859,\n",
       "  131,\n",
       "  52,\n",
       "  173,\n",
       "  33,\n",
       "  97,\n",
       "  29,\n",
       "  230,\n",
       "  907,\n",
       "  161,\n",
       "  245,\n",
       "  79,\n",
       "  267,\n",
       "  104,\n",
       "  906,\n",
       "  70,\n",
       "  69,\n",
       "  73,\n",
       "  203,\n",
       "  135,\n",
       "  230,\n",
       "  53,\n",
       "  907,\n",
       "  99,\n",
       "  273,\n",
       "  88,\n",
       "  53,\n",
       "  56,\n",
       "  75,\n",
       "  122,\n",
       "  68,\n",
       "  906,\n",
       "  49,\n",
       "  38,\n",
       "  53,\n",
       "  199,\n",
       "  232,\n",
       "  109,\n",
       "  28,\n",
       "  78,\n",
       "  906,\n",
       "  52,\n",
       "  42,\n",
       "  123,\n",
       "  196,\n",
       "  53,\n",
       "  101,\n",
       "  121,\n",
       "  78,\n",
       "  906,\n",
       "  236,\n",
       "  67,\n",
       "  112,\n",
       "  27,\n",
       "  153,\n",
       "  53,\n",
       "  80,\n",
       "  80,\n",
       "  673,\n",
       "  114,\n",
       "  63,\n",
       "  243,\n",
       "  211,\n",
       "  311,\n",
       "  311,\n",
       "  311,\n",
       "  23,\n",
       "  235,\n",
       "  909,\n",
       "  909,\n",
       "  909,\n",
       "  125,\n",
       "  170,\n",
       "  256,\n",
       "  63,\n",
       "  33,\n",
       "  138,\n",
       "  907,\n",
       "  146,\n",
       "  79,\n",
       "  162,\n",
       "  129,\n",
       "  82,\n",
       "  243,\n",
       "  908,\n",
       "  67,\n",
       "  79,\n",
       "  239,\n",
       "  213,\n",
       "  28,\n",
       "  40,\n",
       "  137,\n",
       "  908,\n",
       "  70,\n",
       "  39,\n",
       "  98,\n",
       "  162,\n",
       "  255,\n",
       "  150,\n",
       "  36,\n",
       "  907,\n",
       "  180,\n",
       "  92,\n",
       "  117,\n",
       "  116,\n",
       "  82,\n",
       "  233,\n",
       "  907,\n",
       "  88,\n",
       "  33,\n",
       "  124,\n",
       "  87,\n",
       "  83,\n",
       "  251,\n",
       "  155,\n",
       "  907,\n",
       "  96,\n",
       "  69,\n",
       "  105,\n",
       "  219,\n",
       "  28,\n",
       "  123,\n",
       "  146,\n",
       "  907,\n",
       "  89,\n",
       "  91,\n",
       "  143,\n",
       "  34,\n",
       "  83,\n",
       "  232,\n",
       "  155,\n",
       "  907,\n",
       "  96,\n",
       "  155,\n",
       "  54,\n",
       "  89,\n",
       "  199,\n",
       "  112,\n",
       "  33,\n",
       "  72,\n",
       "  745,\n",
       "  158,\n",
       "  106,\n",
       "  18,\n",
       "  103,\n",
       "  48,\n",
       "  38,\n",
       "  85,\n",
       "  98],\n",
       " 'height': [3508,\n",
       "  775,\n",
       "  775,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  26,\n",
       "  41,\n",
       "  26,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  26,\n",
       "  31,\n",
       "  39,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  32,\n",
       "  26,\n",
       "  32,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  26,\n",
       "  37,\n",
       "  31,\n",
       "  26,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  26,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  2,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  36,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  21,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  40,\n",
       "  40,\n",
       "  40,\n",
       "  32,\n",
       "  32,\n",
       "  40,\n",
       "  32,\n",
       "  31,\n",
       "  1230,\n",
       "  775,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  30,\n",
       "  31,\n",
       "  41,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  26,\n",
       "  31,\n",
       "  41,\n",
       "  37,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  36,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  26,\n",
       "  31,\n",
       "  36,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  37,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  37,\n",
       "  26,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  21,\n",
       "  30,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  37,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  26,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  37,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  26,\n",
       "  36,\n",
       "  21,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  36,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  436,\n",
       "  41,\n",
       "  30,\n",
       "  31,\n",
       "  37,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  26,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  30,\n",
       "  26,\n",
       "  31,\n",
       "  32,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  38,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  30,\n",
       "  37,\n",
       "  39,\n",
       "  30,\n",
       "  31,\n",
       "  41,\n",
       "  26,\n",
       "  36,\n",
       "  21,\n",
       "  41,\n",
       "  21,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  37,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  26,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  26,\n",
       "  21,\n",
       "  21,\n",
       "  32,\n",
       "  98,\n",
       "  98,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  33,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  235,\n",
       "  235,\n",
       "  27,\n",
       "  26,\n",
       "  27,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  27,\n",
       "  27,\n",
       "  25,\n",
       "  27,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  25,\n",
       "  27,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  26,\n",
       "  27,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  26,\n",
       "  27,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  26,\n",
       "  33,\n",
       "  33,\n",
       "  33,\n",
       "  25,\n",
       "  26,\n",
       "  33,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  186,\n",
       "  186,\n",
       "  29,\n",
       "  28,\n",
       "  29,\n",
       "  28,\n",
       "  19,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  11,\n",
       "  28,\n",
       "  37,\n",
       "  28,\n",
       "  28,\n",
       "  37,\n",
       "  28,\n",
       "  11,\n",
       "  28,\n",
       "  34,\n",
       "  28,\n",
       "  11,\n",
       "  28,\n",
       "  28,\n",
       "  23,\n",
       "  37,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  37,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  37,\n",
       "  37,\n",
       "  28,\n",
       "  28,\n",
       "  37,\n",
       "  28,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  510,\n",
       "  245,\n",
       "  33,\n",
       "  33,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  31,\n",
       "  25,\n",
       "  31,\n",
       "  21,\n",
       "  30,\n",
       "  31,\n",
       "  26,\n",
       "  26,\n",
       "  31,\n",
       "  26,\n",
       "  31,\n",
       "  21,\n",
       "  30,\n",
       "  31,\n",
       "  3,\n",
       "  26,\n",
       "  32,\n",
       "  26,\n",
       "  31,\n",
       "  21,\n",
       "  30,\n",
       "  31,\n",
       "  3,\n",
       "  27,\n",
       "  34,\n",
       "  34,\n",
       "  33,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  17,\n",
       "  27,\n",
       "  26,\n",
       "  102,\n",
       "  40,\n",
       "  25,\n",
       "  40,\n",
       "  27,\n",
       "  26,\n",
       "  33,\n",
       "  25,\n",
       "  33,\n",
       "  31,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  26,\n",
       "  3,\n",
       "  27,\n",
       "  27,\n",
       "  26,\n",
       "  26,\n",
       "  27,\n",
       "  3,\n",
       "  27,\n",
       "  27,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  3,\n",
       "  117,\n",
       "  117,\n",
       "  34,\n",
       "  33,\n",
       "  26,\n",
       "  25,\n",
       "  25,\n",
       "  26,\n",
       "  26,\n",
       "  3,\n",
       "  27,\n",
       "  26,\n",
       "  25,\n",
       "  25,\n",
       "  25,\n",
       "  27,\n",
       "  3,\n",
       "  33,\n",
       "  33,\n",
       "  26,\n",
       "  25,\n",
       "  25,\n",
       "  33,\n",
       "  26,\n",
       "  3,\n",
       "  186,\n",
       "  186,\n",
       "  37,\n",
       "  28,\n",
       "  28,\n",
       "  29,\n",
       "  28,\n",
       "  37,\n",
       "  37,\n",
       "  19,\n",
       "  37,\n",
       "  28,\n",
       "  37,\n",
       "  19,\n",
       "  28,\n",
       "  37,\n",
       "  28,\n",
       "  28,\n",
       "  37,\n",
       "  23,\n",
       "  28,\n",
       "  37,\n",
       "  28,\n",
       "  28,\n",
       "  28,\n",
       "  19,\n",
       "  19,\n",
       "  37,\n",
       "  19,\n",
       "  37,\n",
       "  29,\n",
       "  28,\n",
       "  23,\n",
       "  37,\n",
       "  28,\n",
       "  37,\n",
       "  144,\n",
       "  144,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  36,\n",
       "  30,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  26,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  30,\n",
       "  31,\n",
       "  26,\n",
       "  380,\n",
       "  380,\n",
       "  41,\n",
       "  30,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  21,\n",
       "  21,\n",
       "  41,\n",
       "  32,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  36,\n",
       "  31,\n",
       "  30,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  41,\n",
       "  21,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  26,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  32,\n",
       "  32,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  436,\n",
       "  436,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  30,\n",
       "  36,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  26,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  36,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  21,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  37,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  32,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  30,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  35,\n",
       "  550,\n",
       "  550,\n",
       "  41,\n",
       "  30,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  26,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  37,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  41,\n",
       "  36,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  36,\n",
       "  30,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  26,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  26,\n",
       "  32,\n",
       "  41,\n",
       "  31,\n",
       "  31,\n",
       "  31,\n",
       "  41,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  41,\n",
       "  26,\n",
       "  41,\n",
       "  32,\n",
       "  31,\n",
       "  41,\n",
       "  32,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  41,\n",
       "  31,\n",
       "  26,\n",
       "  21,\n",
       "  41,\n",
       "  41,\n",
       "  31,\n",
       "  21,\n",
       "  31,\n",
       "  26,\n",
       "  31,\n",
       "  30,\n",
       "  31],\n",
       " 'conf': [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  93,\n",
       "  91,\n",
       "  92,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  92,\n",
       "  92,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  92,\n",
       "  91,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  90,\n",
       "  90,\n",
       "  -1,\n",
       "  96,\n",
       "  92,\n",
       "  92,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  93,\n",
       "  90,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  93,\n",
       "  92,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  59,\n",
       "  80,\n",
       "  96,\n",
       "  94,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  92,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  91,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  93,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  91,\n",
       "  -1,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  90,\n",
       "  90,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  93,\n",
       "  91,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  93,\n",
       "  91,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  90,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  95,\n",
       "  91,\n",
       "  91,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  95,\n",
       "  92,\n",
       "  90,\n",
       "  92,\n",
       "  96,\n",
       "  96,\n",
       "  97,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  93,\n",
       "  -1,\n",
       "  89,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  95,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  91,\n",
       "  -1,\n",
       "  10,\n",
       "  10,\n",
       "  90,\n",
       "  69,\n",
       "  69,\n",
       "  89,\n",
       "  73,\n",
       "  73,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  46,\n",
       "  86,\n",
       "  61,\n",
       "  61,\n",
       "  83,\n",
       "  77,\n",
       "  77,\n",
       "  -1,\n",
       "  95,\n",
       "  94,\n",
       "  49,\n",
       "  49,\n",
       "  96,\n",
       "  65,\n",
       "  75,\n",
       "  -1,\n",
       "  93,\n",
       "  93,\n",
       "  89,\n",
       "  91,\n",
       "  94,\n",
       "  71,\n",
       "  71,\n",
       "  -1,\n",
       "  84,\n",
       "  88,\n",
       "  91,\n",
       "  91,\n",
       "  95,\n",
       "  66,\n",
       "  86,\n",
       "  -1,\n",
       "  95,\n",
       "  94,\n",
       "  90,\n",
       "  91,\n",
       "  96,\n",
       "  77,\n",
       "  77,\n",
       "  -1,\n",
       "  95,\n",
       "  95,\n",
       "  84,\n",
       "  84,\n",
       "  96,\n",
       "  77,\n",
       "  67,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  95,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  95,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  94,\n",
       "  93,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  90,\n",
       "  90,\n",
       "  93,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  93,\n",
       "  93,\n",
       "  95,\n",
       "  93,\n",
       "  93,\n",
       "  95,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  75,\n",
       "  91,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  -1,\n",
       "  93,\n",
       "  91,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  95,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  95,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  55,\n",
       "  72,\n",
       "  76,\n",
       "  -1,\n",
       "  90,\n",
       "  95,\n",
       "  93,\n",
       "  92,\n",
       "  88,\n",
       "  94,\n",
       "  95,\n",
       "  -1,\n",
       "  95,\n",
       "  96,\n",
       "  93,\n",
       "  93,\n",
       "  96,\n",
       "  90,\n",
       "  96,\n",
       "  -1,\n",
       "  93,\n",
       "  91,\n",
       "  92,\n",
       "  92,\n",
       "  96,\n",
       "  91,\n",
       "  95,\n",
       "  -1,\n",
       "  92,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  31,\n",
       "  31,\n",
       "  96,\n",
       "  95,\n",
       "  -1,\n",
       "  -1,\n",
       "  38,\n",
       "  27,\n",
       "  95,\n",
       "  96,\n",
       "  -1,\n",
       "  91,\n",
       "  93,\n",
       "  9,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  95,\n",
       "  91,\n",
       "  -1,\n",
       "  -1,\n",
       "  91,\n",
       "  96,\n",
       "  96,\n",
       "  91,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  91,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  91,\n",
       "  -1,\n",
       "  93,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  91,\n",
       "  -1,\n",
       "  96,\n",
       "  95,\n",
       "  94,\n",
       "  96,\n",
       "  96,\n",
       "  83,\n",
       "  91,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  92,\n",
       "  90,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  93,\n",
       "  -1,\n",
       "  92,\n",
       "  92,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  93,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  97,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  95,\n",
       "  93,\n",
       "  92,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  91,\n",
       "  91,\n",
       "  97,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  95,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  92,\n",
       "  92,\n",
       "  92,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  93,\n",
       "  39,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  89,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  92,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  90,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  92,\n",
       "  80,\n",
       "  96,\n",
       "  95,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  97,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  95,\n",
       "  95,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  96,\n",
       "  94,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  95,\n",
       "  95,\n",
       "  93,\n",
       "  91,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  91,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  95,\n",
       "  95,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  96,\n",
       "  93,\n",
       "  92,\n",
       "  -1,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96,\n",
       "  96],\n",
       " 'text': ['',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'mixed',\n",
       "  'results',\n",
       "  'on',\n",
       "  'the',\n",
       "  'downstream',\n",
       "  'task',\n",
       "  'impact',\n",
       "  'of',\n",
       "  '',\n",
       "  'increasing',\n",
       "  'the',\n",
       "  'pre-trained',\n",
       "  'bi-LM',\n",
       "  'size',\n",
       "  'from',\n",
       "  'two',\n",
       "  '',\n",
       "  'to',\n",
       "  'four',\n",
       "  'layers',\n",
       "  'and',\n",
       "  'Melamud',\n",
       "  'et',\n",
       "  'al.',\n",
       "  '(2016)',\n",
       "  'men-',\n",
       "  '',\n",
       "  'tioned',\n",
       "  'in',\n",
       "  'passing',\n",
       "  'that',\n",
       "  'increasing',\n",
       "  'hidden',\n",
       "  'dimen-',\n",
       "  '',\n",
       "  'sion',\n",
       "  'size',\n",
       "  'from',\n",
       "  '200',\n",
       "  'to',\n",
       "  '600',\n",
       "  'helped,',\n",
       "  'but',\n",
       "  'increasing',\n",
       "  '',\n",
       "  'further',\n",
       "  'to',\n",
       "  '1,000',\n",
       "  'did',\n",
       "  'not',\n",
       "  'bring',\n",
       "  'further',\n",
       "  'improve-',\n",
       "  '',\n",
       "  'ments.',\n",
       "  'Both',\n",
       "  'of',\n",
       "  'these',\n",
       "  'prior',\n",
       "  'works',\n",
       "  'used',\n",
       "  'a',\n",
       "  'feature-',\n",
       "  '',\n",
       "  'based',\n",
       "  'approach',\n",
       "  '—',\n",
       "  'we',\n",
       "  'hypothesize',\n",
       "  'that',\n",
       "  'when',\n",
       "  'the',\n",
       "  '',\n",
       "  'model',\n",
       "  'is',\n",
       "  'fine-tuned',\n",
       "  'directly',\n",
       "  'on',\n",
       "  'the',\n",
       "  'downstream',\n",
       "  '',\n",
       "  'tasks',\n",
       "  'and',\n",
       "  'uses',\n",
       "  'only',\n",
       "  'a',\n",
       "  'very',\n",
       "  'small',\n",
       "  'number',\n",
       "  'of',\n",
       "  'ran-',\n",
       "  '',\n",
       "  'domly',\n",
       "  'initialized',\n",
       "  'additional',\n",
       "  'parameters,',\n",
       "  'the',\n",
       "  'task-',\n",
       "  '',\n",
       "  'specific',\n",
       "  'models',\n",
       "  'can',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'the',\n",
       "  'larger,',\n",
       "  'more',\n",
       "  '',\n",
       "  'expressive',\n",
       "  'pre-trained',\n",
       "  'representations',\n",
       "  'even',\n",
       "  'when',\n",
       "  '',\n",
       "  'downstream',\n",
       "  'task',\n",
       "  'data',\n",
       "  'is',\n",
       "  'very',\n",
       "  'small.',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '5.3.',\n",
       "  'Feature-based',\n",
       "  'Approach',\n",
       "  'with',\n",
       "  'BERT',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'All',\n",
       "  'of',\n",
       "  'the',\n",
       "  'BERT',\n",
       "  'results',\n",
       "  'presented',\n",
       "  'so',\n",
       "  'far',\n",
       "  'have',\n",
       "  'used',\n",
       "  '',\n",
       "  'the',\n",
       "  'fine-tuning',\n",
       "  'approach,',\n",
       "  'where',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'classifi-',\n",
       "  '',\n",
       "  'cation',\n",
       "  'layer',\n",
       "  'is',\n",
       "  'added',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pre-trained',\n",
       "  'model,',\n",
       "  'and',\n",
       "  '',\n",
       "  'all',\n",
       "  'parameters',\n",
       "  'are',\n",
       "  'jointly',\n",
       "  'fine-tuned',\n",
       "  'on',\n",
       "  'a',\n",
       "  'down-',\n",
       "  '',\n",
       "  'stream',\n",
       "  'task.',\n",
       "  'However,',\n",
       "  'the',\n",
       "  'feature-based',\n",
       "  'approach,',\n",
       "  '',\n",
       "  'where',\n",
       "  'fixed',\n",
       "  'features',\n",
       "  'are',\n",
       "  'extracted',\n",
       "  'from',\n",
       "  'the',\n",
       "  'pre-',\n",
       "  '',\n",
       "  'trained',\n",
       "  'model,',\n",
       "  'has',\n",
       "  'certain',\n",
       "  'advantages.',\n",
       "  'First,',\n",
       "  'not',\n",
       "  '',\n",
       "  'all',\n",
       "  'tasks',\n",
       "  'can',\n",
       "  'be',\n",
       "  'easily',\n",
       "  'represented',\n",
       "  'by',\n",
       "  'a',\n",
       "  'Trans-',\n",
       "  '',\n",
       "  'former',\n",
       "  'encoder',\n",
       "  'architecture,',\n",
       "  'and',\n",
       "  'therefore',\n",
       "  'require',\n",
       "  '',\n",
       "  'a',\n",
       "  'task-specific',\n",
       "  'model',\n",
       "  'architecture',\n",
       "  'to',\n",
       "  'be',\n",
       "  'added.',\n",
       "  '',\n",
       "  'Second,',\n",
       "  'there',\n",
       "  'are',\n",
       "  'major',\n",
       "  'computational',\n",
       "  'benefits',\n",
       "  '',\n",
       "  'to',\n",
       "  'pre-compute',\n",
       "  'an',\n",
       "  'expensive',\n",
       "  'representation',\n",
       "  'of',\n",
       "  'the',\n",
       "  '',\n",
       "  'training',\n",
       "  'data',\n",
       "  'once',\n",
       "  'and',\n",
       "  'then',\n",
       "  'run',\n",
       "  'many',\n",
       "  'experiments',\n",
       "  '',\n",
       "  'with',\n",
       "  'cheaper',\n",
       "  'models',\n",
       "  'on',\n",
       "  'top',\n",
       "  'of',\n",
       "  'this',\n",
       "  'representation.',\n",
       "  '',\n",
       "  '',\n",
       "  'In',\n",
       "  'this',\n",
       "  'section,',\n",
       "  'we',\n",
       "  'compare',\n",
       "  'the',\n",
       "  'two',\n",
       "  'approaches',\n",
       "  '',\n",
       "  'by',\n",
       "  'applying',\n",
       "  'BERT',\n",
       "  'to',\n",
       "  'the',\n",
       "  'CoNLL-2003',\n",
       "  'Named',\n",
       "  '',\n",
       "  'Entity',\n",
       "  'Recognition',\n",
       "  '(NER)',\n",
       "  'task',\n",
       "  '(Tjong',\n",
       "  'Kim',\n",
       "  'Sang',\n",
       "  '',\n",
       "  'and',\n",
       "  'De',\n",
       "  'Meulder,',\n",
       "  '2003).',\n",
       "  'In',\n",
       "  'the',\n",
       "  'input',\n",
       "  'to',\n",
       "  'BERT,',\n",
       "  'we',\n",
       "  '',\n",
       "  'use',\n",
       "  'a',\n",
       "  'case-preserving',\n",
       "  'WordPiece',\n",
       "  'model,',\n",
       "  'and',\n",
       "  'we',\n",
       "  '',\n",
       "  'include',\n",
       "  'the',\n",
       "  'maximal',\n",
       "  'document',\n",
       "  'context',\n",
       "  'provided',\n",
       "  '',\n",
       "  'by',\n",
       "  'the',\n",
       "  'data.',\n",
       "  'Following',\n",
       "  'standard',\n",
       "  'practice,',\n",
       "  'we',\n",
       "  'for-',\n",
       "  '',\n",
       "  'mulate',\n",
       "  'this',\n",
       "  'as',\n",
       "  'a',\n",
       "  'tagging',\n",
       "  'task',\n",
       "  'but',\n",
       "  'do',\n",
       "  'not',\n",
       "  'use',\n",
       "  'a',\n",
       "  'CRF',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Hyperparams',\n",
       "  '',\n",
       "  '#L',\n",
       "  ' #H',\n",
       "  '#A',\n",
       "  'LM',\n",
       "  '(ppl)',\n",
       "  'MNLI-m',\n",
       "  'MRPC',\n",
       "  'SST-2',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '3.',\n",
       "  '768',\n",
       "  '12',\n",
       "  '5.84',\n",
       "  '71.9',\n",
       "  '79.8',\n",
       "  '88.4',\n",
       "  '',\n",
       "  '6',\n",
       "  '768',\n",
       "  '3',\n",
       "  '5.24',\n",
       "  '80.6',\n",
       "  '82.2',\n",
       "  '90.7',\n",
       "  '',\n",
       "  '6',\n",
       "  '768',\n",
       "  '12',\n",
       "  '4.68',\n",
       "  '81.9',\n",
       "  '84.8',\n",
       "  '91.3',\n",
       "  '',\n",
       "  '12',\n",
       "  '768',\n",
       "  '12',\n",
       "  '3.99',\n",
       "  '84.4',\n",
       "  '86.7',\n",
       "  '92.9',\n",
       "  '',\n",
       "  '12',\n",
       "  '1024',\n",
       "  '16',\n",
       "  '3.54',\n",
       "  '85.7',\n",
       "  '86.9',\n",
       "  '93.3',\n",
       "  '',\n",
       "  '24',\n",
       "  '1024',\n",
       "  '16',\n",
       "  '3.23',\n",
       "  '86.6',\n",
       "  '87.8',\n",
       "  '93.7',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Dev',\n",
       "  'Set',\n",
       "  'Accuracy',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ' ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ' ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Table',\n",
       "  '6:',\n",
       "  'Ablation',\n",
       "  'over',\n",
       "  'BERT',\n",
       "  'model',\n",
       "  'size.',\n",
       "  '#L',\n",
       "  '=',\n",
       "  'the',\n",
       "  '',\n",
       "  'number',\n",
       "  'of',\n",
       "  'layers;',\n",
       "  '#H',\n",
       "  '=',\n",
       "  'hidden',\n",
       "  'size;',\n",
       "  '#A',\n",
       "  '=',\n",
       "  'number',\n",
       "  'of',\n",
       "  'at-',\n",
       "  '',\n",
       "  'tention',\n",
       "  'heads.',\n",
       "  '“LM',\n",
       "  '(ppl)”',\n",
       "  'is',\n",
       "  'the',\n",
       "  'masked',\n",
       "  'LM',\n",
       "  'perplexity',\n",
       "  '',\n",
       "  'of',\n",
       "  'held-out',\n",
       "  'training',\n",
       "  'data.',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ' ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ' ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'System',\n",
       "  'Dev',\n",
       "  'Fl',\n",
       "  'Test',\n",
       "  'Fl',\n",
       "  '',\n",
       "  'ELMo',\n",
       "  '(Peters',\n",
       "  'et',\n",
       "  'al.,',\n",
       "  '2018a)',\n",
       "  '95.7',\n",
       "  '92.2',\n",
       "  '',\n",
       "  'CVT',\n",
       "  '(Clark',\n",
       "  'et',\n",
       "  'al.,',\n",
       "  '2018)',\n",
       "  '-',\n",
       "  '92.6',\n",
       "  '',\n",
       "  'CSE',\n",
       "  '(Akbik',\n",
       "  'et',\n",
       "  'al.,',\n",
       "  '2018)',\n",
       "  '-',\n",
       "  '93.1',\n",
       "  '',\n",
       "  'Fine-tuning',\n",
       "  'approach',\n",
       "  '',\n",
       "  '',\n",
       "  'BERT',\n",
       "  'LarGE',\n",
       "  '96.6',\n",
       "  '92.8',\n",
       "  '',\n",
       "  '',\n",
       "  'BERT',\n",
       "  'sase',\n",
       "  '96.4',\n",
       "  '92.4',\n",
       "  '',\n",
       "  'Feature-based',\n",
       "  'approach',\n",
       "  '(BERTgasg)',\n",
       "  '',\n",
       "  '',\n",
       "  'Embeddings',\n",
       "  '91.0',\n",
       "  '-',\n",
       "  '',\n",
       "  '',\n",
       "  'Second-to-Last',\n",
       "  'Hidden',\n",
       "  '95.6',\n",
       "  '-',\n",
       "  '',\n",
       "  '',\n",
       "  'Last',\n",
       "  'Hidden',\n",
       "  '94.9',\n",
       "  '-',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Weighted',\n",
       "  'Sum',\n",
       "  'Last',\n",
       "  'Four',\n",
       "  'Hidden',\n",
       "  '95.9',\n",
       "  '-',\n",
       "  '',\n",
       "  'Concat',\n",
       "  'Last',\n",
       "  'Four',\n",
       "  'Hidden',\n",
       "  '96.1',\n",
       "  '-',\n",
       "  '',\n",
       "  'Weighted',\n",
       "  'Sum',\n",
       "  'All',\n",
       "  '12',\n",
       "  'Layers',\n",
       "  '95.5',\n",
       "  '-',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Table',\n",
       "  '7:',\n",
       "  'CoNLL-2003',\n",
       "  'Named',\n",
       "  'Entity',\n",
       "  'Recognition',\n",
       "  're-',\n",
       "  '',\n",
       "  'sults.',\n",
       "  'Hyperparameters',\n",
       "  'were',\n",
       "  'selected',\n",
       "  'using',\n",
       "  'the',\n",
       "  'Dev',\n",
       "  '',\n",
       "  'set.',\n",
       "  'The',\n",
       "  'reported',\n",
       "  'Dev',\n",
       "  'and',\n",
       "  'Test',\n",
       "  'scores',\n",
       "  'are',\n",
       "  'averaged',\n",
       "  'over',\n",
       "  '',\n",
       "  '5',\n",
       "  'random',\n",
       "  'restarts',\n",
       "  'using',\n",
       "  'those',\n",
       "  'hyperparameters.',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'layer',\n",
       "  'in',\n",
       "  'the',\n",
       "  'output.',\n",
       "  'We',\n",
       "  'use',\n",
       "  'the',\n",
       "  'representation',\n",
       "  'of',\n",
       "  '',\n",
       "  'the',\n",
       "  'first',\n",
       "  'sub-token',\n",
       "  'as',\n",
       "  'the',\n",
       "  'input',\n",
       "  'to',\n",
       "  'the',\n",
       "  'token-level',\n",
       "  '',\n",
       "  'classifier',\n",
       "  'over',\n",
       "  'the',\n",
       "  'NER',\n",
       "  'label',\n",
       "  'set.',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'To',\n",
       "  'ablate',\n",
       "  'the',\n",
       "  'fine-tuning',\n",
       "  'approach,',\n",
       "  'we',\n",
       "  'apply',\n",
       "  'the',\n",
       "  '',\n",
       "  'feature-based',\n",
       "  'approach',\n",
       "  'by',\n",
       "  'extracting',\n",
       "  'the',\n",
       "  'activa-',\n",
       "  '',\n",
       "  'tions',\n",
       "  'from',\n",
       "  'one',\n",
       "  'or',\n",
       "  'more',\n",
       "  'layers',\n",
       "  'without',\n",
       "  'fine-tuning',\n",
       "  '',\n",
       "  'any',\n",
       "  'parameters',\n",
       "  'of',\n",
       "  'BERT.',\n",
       "  'These',\n",
       "  'contextual',\n",
       "  'em-',\n",
       "  '',\n",
       "  'beddings',\n",
       "  'are',\n",
       "  'used',\n",
       "  'as',\n",
       "  'input',\n",
       "  'to',\n",
       "  'a',\n",
       "  'randomly',\n",
       "  'initial-',\n",
       "  '',\n",
       "  'ized',\n",
       "  'two-layer',\n",
       "  '768-dimensional',\n",
       "  'BiLSTM',\n",
       "  'before',\n",
       "  '',\n",
       "  'the',\n",
       "  'classification',\n",
       "  'layer.',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Results',\n",
       "  'are',\n",
       "  'presented',\n",
       "  'in',\n",
       "  'Table',\n",
       "  '7.',\n",
       "  'BERTLarGE',\n",
       "  '',\n",
       "  'performs',\n",
       "  'competitively',\n",
       "  'with',\n",
       "  'state-of-the-art',\n",
       "  'meth-',\n",
       "  '',\n",
       "  'ods.',\n",
       "  'The',\n",
       "  'best',\n",
       "  'performing',\n",
       "  'method',\n",
       "  'concatenates',\n",
       "  'the',\n",
       "  '',\n",
       "  'token',\n",
       "  'representations',\n",
       "  'from',\n",
       "  'the',\n",
       "  'top',\n",
       "  'four',\n",
       "  'hidden',\n",
       "  'lay-',\n",
       "  '',\n",
       "  'ers',\n",
       "  'of',\n",
       "  'the',\n",
       "  'pre-trained',\n",
       "  'Transformer,',\n",
       "  'which',\n",
       "  'is',\n",
       "  'only',\n",
       "  '',\n",
       "  '0.3',\n",
       "  'F1',\n",
       "  'behind',\n",
       "  'fine-tuning',\n",
       "  'the',\n",
       "  'entire',\n",
       "  'model.',\n",
       "  'This',\n",
       "  '',\n",
       "  'demonstrates',\n",
       "  'that',\n",
       "  'BERT',\n",
       "  'is',\n",
       "  'effective',\n",
       "  'for',\n",
       "  'both',\n",
       "  'fine-',\n",
       "  '',\n",
       "  'tuning',\n",
       "  'and',\n",
       "  'feature-based',\n",
       "  'approaches.',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '6',\n",
       "  'Conclusion',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Recent',\n",
       "  'empirical',\n",
       "  'improvements',\n",
       "  'due',\n",
       "  'to',\n",
       "  'transfer',\n",
       "  '',\n",
       "  'learning',\n",
       "  'with',\n",
       "  'language',\n",
       "  'models',\n",
       "  'have',\n",
       "  'demonstrated',\n",
       "  '',\n",
       "  'that',\n",
       "  'rich,',\n",
       "  'unsupervised',\n",
       "  'pre-training',\n",
       "  'is',\n",
       "  'an',\n",
       "  'integral',\n",
       "  '',\n",
       "  'part',\n",
       "  'of',\n",
       "  'many',\n",
       "  'language',\n",
       "  'understanding',\n",
       "  'systems.',\n",
       "  'In',\n",
       "  '',\n",
       "  'particular,',\n",
       "  'these',\n",
       "  'results',\n",
       "  'enable',\n",
       "  'even',\n",
       "  'low-resource',\n",
       "  '',\n",
       "  'tasks',\n",
       "  'to',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'deep',\n",
       "  'unidirectional',\n",
       "  'architec-',\n",
       "  '',\n",
       "  'tures.',\n",
       "  'Our',\n",
       "  'major',\n",
       "  'contribution',\n",
       "  'is',\n",
       "  'further',\n",
       "  'general-',\n",
       "  '',\n",
       "  'izing',\n",
       "  'these',\n",
       "  'findings',\n",
       "  'to',\n",
       "  'deep',\n",
       "  'bidirectional',\n",
       "  'architec-',\n",
       "  '',\n",
       "  'tures,',\n",
       "  'allowing',\n",
       "  'the',\n",
       "  'same',\n",
       "  'pre-trained',\n",
       "  'model',\n",
       "  'to',\n",
       "  'suc-',\n",
       "  '',\n",
       "  'cessfully',\n",
       "  'tackle',\n",
       "  'a',\n",
       "  'broad',\n",
       "  'set',\n",
       "  'of',\n",
       "  'NLP',\n",
       "  'tasks.']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "\n",
    "# Load the image\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/opt/homebrew/bin/tesseract\"\n",
    "image_path = \"1810.04805v2_output/images/page_9.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert image to grayscale for better OCR accuracy\n",
    "gray = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Use OCR to extract text\n",
    "extracted_text = pytesseract.image_to_string(gray)\n",
    "\n",
    "# Use OCR to detect tables as well\n",
    "extracted_tables = pytesseract.image_to_data(gray, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "def save_markdown(text, tables, output_md):\n",
    "    \"\"\"Save extracted text and tables in a Markdown file\"\"\"\n",
    "    markdown_content = \"\"\n",
    "\n",
    "    # Add text section\n",
    "    markdown_content += f\"<text>\\n{text.strip()}\\n</text>\\n\\n\"\n",
    "\n",
    "    # Add table section\n",
    "    for table in tables:\n",
    "        markdown_content += \"<tbl>\\n\"\n",
    "        for row in table:\n",
    "            row_md = \"| \" + \" | \".join(str(cell) if cell else \" \" for cell in row) + \" |\"\n",
    "            markdown_content += row_md + \"\\n\"\n",
    "        markdown_content += \"</tbl>\\n\\n\"\n",
    "\n",
    "    # Save to Markdown file\n",
    "    with open(output_md, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "\n",
    "    print(f\"Markdown file saved as {output_md}\")\n",
    "\n",
    "output_markdown_file = \"output.md\"\n",
    "save_markdown(extracted_text, extracted_tables,output_markdown_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown file saved as output.md\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import os\n",
    "\n",
    "# Set Tesseract Path (Modify this if needed)\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/opt/homebrew/bin/tesseract\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from all pages of a PDF using pdfplumber.\"\"\"\n",
    "    extracted_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                extracted_text += f\"\\n<text>\\nPage {i+1}\\n{text.strip()}\\n</text>\\n\\n\"\n",
    "    return extracted_text\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts tables from a PDF and converts them to Markdown.\"\"\"\n",
    "    tables_md = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                tables_md += f\"\\n<tbl>\\nPage {i+1}\\n\"\n",
    "                for row in table:\n",
    "                    row_md = \"| \" + \" | \".join(str(cell) if cell else \" \" for cell in row) + \" |\"\n",
    "                    tables_md += row_md + \"\\n\"\n",
    "                tables_md += \"</tbl>\\n\\n\"\n",
    "    return tables_md\n",
    "\n",
    "def save_markdown(pdf_path, output_md):\n",
    "    \"\"\"Processes the entire PDF and saves the extracted text and tables in Markdown format.\"\"\"\n",
    "    markdown_content = \"\"\n",
    "\n",
    "    # Extract text\n",
    "    markdown_content += extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Extract tables\n",
    "    markdown_content += extract_tables_from_pdf(pdf_path)\n",
    "\n",
    "    # Save to Markdown file\n",
    "    with open(output_md, \"w\", encoding=\"utf-8\") as md_file:\n",
    "        md_file.write(markdown_content)\n",
    "\n",
    "    print(f\"Markdown file saved as {output_md}\")\n",
    "\n",
    "# Example Usage\n",
    "pdf_file = \"1810.04805v2.pdf\"  # Replace with your PDF file path\n",
    "output_markdown_file = \"output.md\"\n",
    "save_markdown(pdf_file, output_markdown_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2table.document import Image\n",
    "\n",
    "# Instantiation of the image\n",
    "img = Image(src=\"1810.04805v2_output/images/page_9.png\")\n",
    "\n",
    "# Table identification\n",
    "imgage_tables = img.extract_tables()\n",
    "\n",
    "# Result of table identification\n",
    "imgage_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: img2table in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: polars>=1.2 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from polars[pandas]>=1.2->img2table) (1.22.0)\n",
      "Requirement already satisfied: pyarrow>=7 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from img2table) (19.0.0)\n",
      "Requirement already satisfied: numpy in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from img2table) (1.26.4)\n",
      "Requirement already satisfied: pypdfium2==4.30.0 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from img2table) (4.30.0)\n",
      "Requirement already satisfied: opencv-contrib-python>=4 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from img2table) (4.11.0.86)\n",
      "Requirement already satisfied: numba in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from img2table) (0.60.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from img2table) (4.12.3)\n",
      "Requirement already satisfied: xlsxwriter>=3.0.6 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from img2table) (3.2.2)\n",
      "Requirement already satisfied: pandas in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from polars[pandas]>=1.2->img2table) (2.2.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from beautifulsoup4->img2table) (2.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from numba->img2table) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from pandas->polars[pandas]>=1.2->img2table) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from pandas->polars[pandas]>=1.2->img2table) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from pandas->polars[pandas]>=1.2->img2table) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->polars[pandas]>=1.2->img2table) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install img2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from img2table.document import PDF\n",
    "from img2table.ocr import TesseractOCR\n",
    "\n",
    "# Instantiation of the pdf\n",
    "pdf = PDF(src=\"1810.04805v2.pdf\")\n",
    "print(\"building ocr\")\n",
    "# Instantiation of the OCR, Tesseract, which requires prior installation\n",
    "ocr = TesseractOCR(lang=\"eng\")\n",
    "print(\"ocr built\")\n",
    "print(\"extracting tables\")\n",
    "# Table identification and extraction\n",
    "pdf_tables = pdf.extract_tables(ocr=ocr)\n",
    "\n",
    "\n",
    "pdf_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting camelot\n",
      "  Downloading Camelot-12.06.29.tar.gz (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting SQLAlchemy<0.8.0,>=0.7.7 (from camelot)\n",
      "  Downloading SQLAlchemy-0.7.10.tar.gz (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Elixir>=0.7.1 (from camelot)\n",
      "  Downloading Elixir-0.7.1.tar.gz (47 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sqlalchemy-migrate>=0.7.1 (from camelot)\n",
      "  Downloading sqlalchemy_migrate-0.13.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: Jinja2>=2.5.5 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from camelot) (3.1.5)\n",
      "Requirement already satisfied: chardet>=1.0.1 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from camelot) (5.2.0)\n",
      "Collecting xlwt==0.7.2 (from camelot)\n",
      "  Downloading xlwt-0.7.2.zip (131 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting xlrd==0.7.1 (from camelot)\n",
      "  Downloading xlrd-0.7.1.zip (125 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from Jinja2>=2.5.5->camelot) (3.0.2)\n",
      "Collecting pbr>=1.8 (from sqlalchemy-migrate>=0.7.1->camelot)\n",
      "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "INFO: pip is looking at multiple versions of sqlalchemy-migrate to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sqlalchemy-migrate>=0.7.1 (from camelot)\n",
      "  Downloading sqlalchemy_migrate-0.12.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading sqlalchemy-migrate-0.11.0.tar.gz (128 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: decorator in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from sqlalchemy-migrate>=0.7.1->camelot) (5.1.1)\n",
      "Requirement already satisfied: six>=1.7.0 in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from sqlalchemy-migrate>=0.7.1->camelot) (1.17.0)\n",
      "Collecting sqlparse (from sqlalchemy-migrate>=0.7.1->camelot)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting Tempita>=0.4 (from sqlalchemy-migrate>=0.7.1->camelot)\n",
      "  Downloading Tempita-0.6.0-py3-none-any.whl.metadata (972 bytes)\n",
      "Requirement already satisfied: setuptools in /Users/lishuyao/miniconda3/envs/odprt/lib/python3.9/site-packages (from pbr>=1.8->sqlalchemy-migrate>=0.7.1->camelot) (75.8.0)\n",
      "Using cached pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
      "Downloading Tempita-0.6.0-py3-none-any.whl (13 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Building wheels for collected packages: camelot, xlrd, xlwt, Elixir, SQLAlchemy, sqlalchemy-migrate\n",
      "  Building wheel for camelot (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for camelot: filename=Camelot-12.6.29-py3-none-any.whl size=3919149 sha256=76e0ecbedc8ab123dab8b0f4adf7b76218a2512a57dc34e03241a5da157b9e53\n",
      "  Stored in directory: /Users/lishuyao/Library/Caches/pip/wheels/e7/17/d7/0ec12f21b8d39da9f511cc4b5313378985559a4024512b9b3a\n",
      "  Building wheel for xlrd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for xlrd: filename=xlrd-0.7.1-py3-none-any.whl size=118021 sha256=bc1a90820e83f952851b7f34a23579a472087f0798f986a645c30a8f36de272d\n",
      "  Stored in directory: /Users/lishuyao/Library/Caches/pip/wheels/9d/2c/d7/b2313c6d33d1b46b780b3c50b8587bbc7a0b19915de6dd1465\n",
      "  Building wheel for xlwt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for xlwt: filename=xlwt-0.7.2-py3-none-any.whl size=120277 sha256=f3581aaa88d4bcc433e4cdfe9e19230815fe710d2c017a0e8cbf614acb966059\n",
      "  Stored in directory: /Users/lishuyao/Library/Caches/pip/wheels/42/55/c8/53b1d1516f9dc38880b0cc542d6fcafdcd88774485d57bac08\n",
      "  Building wheel for Elixir (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Elixir: filename=Elixir-0.7.1-py3-none-any.whl size=53933 sha256=579d2ae5a5dad9bcda17d669ee57dab4786ba286ab1e8c7aba752683f996e124\n",
      "  Stored in directory: /Users/lishuyao/Library/Caches/pip/wheels/1b/7c/78/156c68138300f6f390961644d49495828502d82663648821ad\n",
      "  Building wheel for SQLAlchemy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for SQLAlchemy: filename=SQLAlchemy-0.7.10-py3-none-any.whl size=696333 sha256=2980b67feae2d9739e4e7fa39e8e3924e69fa21c7ab3137fa7e51b5ec909d414\n",
      "  Stored in directory: /Users/lishuyao/Library/Caches/pip/wheels/25/f9/79/f614cbdaacf6f87df3183696daa04211ef00a2b394733e87bb\n",
      "  Building wheel for sqlalchemy-migrate (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlalchemy-migrate: filename=sqlalchemy_migrate-0.11.0-py3-none-any.whl size=108894 sha256=558ee3bbb5fea23782785300202a8b68e9b9d752ba0e25b3453adc9a3406ddce\n",
      "  Stored in directory: /Users/lishuyao/Library/Caches/pip/wheels/5e/7b/87/05a80276e91eb3fe2d0165c3d9bee787953902906c8acce279\n",
      "Successfully built camelot xlrd xlwt Elixir SQLAlchemy sqlalchemy-migrate\n",
      "Installing collected packages: xlwt, xlrd, Tempita, SQLAlchemy, sqlparse, pbr, Elixir, sqlalchemy-migrate, camelot\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.38\n",
      "    Uninstalling SQLAlchemy-2.0.38:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.38\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.18 requires SQLAlchemy<3,>=1.4, but you have sqlalchemy 0.7.10 which is incompatible.\n",
      "langchain-community 0.3.17 requires SQLAlchemy<3,>=1.4, but you have sqlalchemy 0.7.10 which is incompatible.\n",
      "llama-index-core 0.12.16.post1 requires SQLAlchemy[asyncio]>=1.4.49, but you have sqlalchemy 0.7.10 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Elixir-0.7.1 SQLAlchemy-0.7.10 Tempita-0.6.0 camelot-12.6.29 pbr-6.1.1 sqlalchemy-migrate-0.11.0 sqlparse-0.5.3 xlrd-0.7.1 xlwt-0.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install camelot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'camelot' has no attribute 'read_pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcamelot\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mcamelot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pdf\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1810.04805v2.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m tables[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdf\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'camelot' has no attribute 'read_pdf'"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "tables = camelot.read_pdf('1810.04805v2.pdf')\n",
    "tables[0].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_user_files(fname):\n",
    "    # handle different file types\n",
    "    if fname.endswith('.csv'):\n",
    "        pass\n",
    "    elif fname.endswith('.xml'):\n",
    "        pass\n",
    "    elif fname.endswith('.pptx'):\n",
    "        pass\n",
    "    elif fname.endswith('.docx'):\n",
    "        pass\n",
    "    elif fname.endswith('.pdf'):\n",
    "        pass\n",
    "    elif fname.endswith('.txt'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add the root directory to sys.path\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from chatbot.backend.document_parser.document_parser import DocumentParser\n",
    "docParser = DocumentParser()\n",
    "extracted_images = docParser.extract_images_from_pdf('/Users/lishuyao/Documents/NUS/MODS/Y3S2/Capstone/ODPRT-chatbot/notebooks/1810.04805v2.pdf')\n",
    "print(\"image extracted\")\n",
    "for img in extracted_images:\n",
    "    print(\"displaying image\")\n",
    "    display(img)  # Displays images inline in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ No text found on Page 1\n",
      "❌ No text found on Page 2\n",
      "❌ No text found on Page 3\n",
      "⚠️ No text extracted from the entire PDF. It might contain images instead of text.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "def extract_text_from_pdf(file_path: str):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    extracted_text = \"\"\n",
    "    \n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                print(f\"✅ Extracted Text from Page {i+1}:\\n{text}\\n\")  # Debug print\n",
    "                extracted_text += f\"\\nPage {i+1}\\n{text.strip()}\\n\\n\"\n",
    "            else:\n",
    "                print(f\"❌ No text found on Page {i+1}\")\n",
    "\n",
    "    if not extracted_text:\n",
    "        print(\"⚠️ No text extracted from the entire PDF. It might contain images instead of text.\")\n",
    "    \n",
    "    return extracted_text\n",
    "\n",
    "extract_text_from_pdf(\"/Users/lishuyao/Documents/NUS/MODS/Y3S2/Capstone/ODPRT-chatbot/processed_docs/emails_with_attachments/Agreement Type 01-01/processed_attachments/Extension and  Virement Request for JSA Polder project_NUS_processed_processed.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted OCR Text from Page 1:\n",
      "College of Design and Engineering\n",
      "Dean’s Office\n",
      "\n",
      "NUS\n",
      "\n",
      "National University\n",
      "of Singapore\n",
      "\n",
      "14\" Dec 2023\n",
      "\n",
      "To: Mr. Tan Yeow Cheong\n",
      "Director (Land Reclamation)\n",
      "Housing & Development Board\n",
      "\n",
      "Subject: Proposed Extension and Fund Virement of the JSA (Polder) Project\n",
      "\n",
      "Dear Mr Tan,\n",
      "\n",
      "lam writing to formally request an extension of the project ending date for the Joint Study on\n",
      "Advanced Geohydrological and Geotechnical Instrumentations for the Construction of\n",
      "Polder (JSA Polder Project, WBS no: A-0005466-01-00), which has been a vital joint-study\n",
      "between Housing & Development Board (HDB) and National University of Singapore (NUS)\n",
      "since 2019.\n",
      "\n",
      "The letter will outline the reasons for extending the project beyond its original timeline, as\n",
      "detailed below, as well as the reasons for the funding virement.\n",
      "\n",
      "Original Project Timeline: 2\"4 January 2019 to 2\"! January 2024\n",
      "Proposed new project end date: 315t December 2024\n",
      "\n",
      "A. Justification for the Project Extension:\n",
      "\n",
      "1. Testing and Validation of a Revised Reduced-Size Resistivity Measuring Device:\n",
      "\n",
      "One of the key achievements of this project so far is the successful development of a device\n",
      "capable of measuring the resistivity of the CB (cement-bentonite) material during the curing\n",
      "process. This resistivity value will then be correlated to the unconfined compressive strength\n",
      "(UCS) and permeability (k) of the CB material. Two numbers of this device have been installed\n",
      "in-situ at the sacrificial panels and very consistent and excellent results were obtained.\n",
      "\n",
      "However, the consultant had one concern on this device: the size of the device may be too\n",
      "large (as it consists of 4 legs), such that it may affect the integrity of the CB wall. Hence, the\n",
      "NUS team further researched into this, and developed a reduced-size resistivity measuring\n",
      "device (75% reduction in size compared to previous version, and consists of only 1 leg). Thus,\n",
      "significantly reducing the size of the device to address the consultant’s concern.\n",
      "\n",
      "As a result of these modifications, it is imperative to test and validate the revised reduced-size\n",
      "resistivity device extensively. This validation process involves conducting resistivity tests\n",
      "across, preferably, at least two more CB walls (actual panels or sacrificial panels) to assess and\n",
      "validate the device’s performance.\n",
      "\n",
      "✅ Extracted OCR Text from Page 2:\n",
      "College of Design and Engineering B® N US\n",
      "Dean’s Office\n",
      "\n",
      "National University\n",
      "of Singapore\n",
      "\n",
      "We have just successfully installed two revised reduced-size resistivity devices into CB walls\n",
      "(actual panels) during the month of December 2023. Thus, there is a necessity to have some\n",
      "extra time to monitor the performance and to thoroughly review the findings, ensuring an in-\n",
      "depth examination of the device's performance under real wall conditions. The extended\n",
      "project timeline will give us adequate time to conduct comprehensive testing and validation\n",
      "of the revised reduced-size resistivity device. This rigorous testing is important to establish a\n",
      "reliable correlation between the readings of this device and the in-situ CB’s properties, which\n",
      "is much needed for possible future applications of this device. This, in turn, will result in time\n",
      "and cost savings compared to the current coring method for properties determination.\n",
      "\n",
      "2. Study into the in-situ measurement of permeability of top sand layer:\n",
      "\n",
      "Initially, the project emphasis and focus were placed on the study of CB Wall's properties and\n",
      "the QA/QC check of the Deep Cement Mixing (DCM) columns so that we can effectively support\n",
      "the on-site construction activities. As a result, the study on evaluating sand layer permeability\n",
      "using a non-destructive in-situ method was deferred till the on-site activities had completed.\n",
      "Nevertheless, a non-destructive, in-situ testing method to determine the permeability of\n",
      "sandy soil was developed in the NUS laboratory. However, to ensure a comprehensive\n",
      "understanding of the sand layer’s permeability changes with time and environmental\n",
      "conditions, and their impact on polder function, we would like to request an extension of the\n",
      "project timeline to conduct a more in-depth study on sand permeability issue.\n",
      "\n",
      "The proposed revised schedule for the above-mentioned activities is shown below:\n",
      "\n",
      "Resistivity Measurement Device\n",
      "\n",
      "In-situ measurement of sand\n",
      "permeability\n",
      "\n",
      "We are also proposing to continue the current practice of having the quarterly progress\n",
      "meeting with you and your engineers into the extended period.\n",
      "\n",
      "B. Proposed Virement of Fund:\n",
      "\n",
      "In conjunction with the extension of project duration, we would also like to propose the following\n",
      "virement of funds, without requesting for additional funding:\n",
      "(i) to transfer $20,000.00 from the \"Overseas Travel\" category to the \"Equipment\"\n",
      "category.\n",
      "(ii) to transfer $25,000.00 from the \"Manpower\" category to the \" Equipment\"\n",
      "category, and\n",
      "(iii) to transfer $55,000.00 from the \"Manpower\" category to the \" Other Operating\n",
      "Expense\" category,\n",
      "\n",
      "It is required to increase the funding for Equipment and Other Operating Expenses (OOE)\n",
      "because of the decision to implement revised, reduced-size in-situ resistivity measurement\n",
      "\n",
      "2\n",
      "\n",
      "✅ Extracted OCR Text from Page 3:\n",
      "College of Design and Engineering\n",
      "Dean’s Office\n",
      "\n",
      "NUS\n",
      "\n",
      "National University\n",
      "of Singapore\n",
      "\n",
      "devices (RMD). While the initial installation of RMDs adhered to the allocated budget, the\n",
      "consultant's suggestion for revised devices of smaller sizes requires funding to research,\n",
      "fabricate, install, and monitor these updated versions within the CB wall panel. It is imperative\n",
      "to ensure adequate financial support for crucial project components, such as the fabrication of\n",
      "more resistivity devices for installations, procure more dataloggers with sustainable solar panel\n",
      "systems for autonomous data collection, and conduct laboratory and field tests for the study\n",
      "of in-situ measurement of permeability of top sand layer.\n",
      "\n",
      "There has been an underutilization of funds under the category for Manpower (EoM) and\n",
      "Overseas travel, as the recruitment of researchers materialized a bit later than originally\n",
      "planned, and the number of overseas conference trips were reduced due to COVID-19. Hence,\n",
      "it is proposed to reallocate the funds in Manpower (EoM) and Overseas Travel to Equipment\n",
      "and Other Operating Expenses (OOE). NUS has assessed that there are sufficient funds available\n",
      "in the remaining budget for Manpower and for Overseas Travel in 2024 after the virement.\n",
      "\n",
      "The budget, before and after this proposed virement, is summarized below.\n",
      "\n",
      "Total Budgeted: $1,124,132.00\n",
      "Leftover money: $710,040.90 as of 13‘ Dec 2023.\n",
      "\n",
      ". Manpower (EoM) $730,416.67 $459,620.19 - $80,000.00 | $650,416.67 $379,620.19\n",
      "2. Equipment $47,000.00 $1,056.61 + $45,000.00 | $92,000.00 $46,056.61\n",
      "3. Consumables\n",
      "\n",
      "a. Other Operating $87,360.00 $1,983.11 + $55,000.00 | $142,360.00 $56,983.11\n",
      "Expenses (OOE)\n",
      "b. Overseas Travel $72,000.00 $60,025.66 - $20,000.00 | $52,000.00 $40,025.66\n",
      "4. Others (i.e. NUS $187,355.33 $187,355.33 - - $187,355.33\n",
      "Indirect Costs)\n",
      "Total | $1,124,132.00 $710,040.90 - $1,124,132.00 | $710,040.90\n",
      "\n",
      "Should you require any additional information or have any queries regarding this proposal,\n",
      "please do not hesitate to contact me at ceecsh@nus.edu.sg . Thank you for your time and\n",
      "consideration.\n",
      "\n",
      "Yours sincerely,\n",
      "\n",
      "Ch\n",
      "\n",
      "——\n",
      "Dr CHEW Soon Hoe\n",
      "\n",
      "Asst Professor\n",
      "\n",
      "Department of Civil and Environmental Engineering\n",
      "National University of Singapore\n",
      "\n",
      "PI for JSA (Polder) project.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nPage 1\\nCollege of Design and Engineering\\nDean’s Office\\n\\nNUS\\n\\nNational University\\nof Singapore\\n\\n14\" Dec 2023\\n\\nTo: Mr. Tan Yeow Cheong\\nDirector (Land Reclamation)\\nHousing & Development Board\\n\\nSubject: Proposed Extension and Fund Virement of the JSA (Polder) Project\\n\\nDear Mr Tan,\\n\\nlam writing to formally request an extension of the project ending date for the Joint Study on\\nAdvanced Geohydrological and Geotechnical Instrumentations for the Construction of\\nPolder (JSA Polder Project, WBS no: A-0005466-01-00), which has been a vital joint-study\\nbetween Housing & Development Board (HDB) and National University of Singapore (NUS)\\nsince 2019.\\n\\nThe letter will outline the reasons for extending the project beyond its original timeline, as\\ndetailed below, as well as the reasons for the funding virement.\\n\\nOriginal Project Timeline: 2\"4 January 2019 to 2\"! January 2024\\nProposed new project end date: 315t December 2024\\n\\nA. Justification for the Project Extension:\\n\\n1. Testing and Validation of a Revised Reduced-Size Resistivity Measuring Device:\\n\\nOne of the key achievements of this project so far is the successful development of a device\\ncapable of measuring the resistivity of the CB (cement-bentonite) material during the curing\\nprocess. This resistivity value will then be correlated to the unconfined compressive strength\\n(UCS) and permeability (k) of the CB material. Two numbers of this device have been installed\\nin-situ at the sacrificial panels and very consistent and excellent results were obtained.\\n\\nHowever, the consultant had one concern on this device: the size of the device may be too\\nlarge (as it consists of 4 legs), such that it may affect the integrity of the CB wall. Hence, the\\nNUS team further researched into this, and developed a reduced-size resistivity measuring\\ndevice (75% reduction in size compared to previous version, and consists of only 1 leg). Thus,\\nsignificantly reducing the size of the device to address the consultant’s concern.\\n\\nAs a result of these modifications, it is imperative to test and validate the revised reduced-size\\nresistivity device extensively. This validation process involves conducting resistivity tests\\nacross, preferably, at least two more CB walls (actual panels or sacrificial panels) to assess and\\nvalidate the device’s performance.\\n\\n\\nPage 2\\nCollege of Design and Engineering B® N US\\nDean’s Office\\n\\nNational University\\nof Singapore\\n\\nWe have just successfully installed two revised reduced-size resistivity devices into CB walls\\n(actual panels) during the month of December 2023. Thus, there is a necessity to have some\\nextra time to monitor the performance and to thoroughly review the findings, ensuring an in-\\ndepth examination of the device\\'s performance under real wall conditions. The extended\\nproject timeline will give us adequate time to conduct comprehensive testing and validation\\nof the revised reduced-size resistivity device. This rigorous testing is important to establish a\\nreliable correlation between the readings of this device and the in-situ CB’s properties, which\\nis much needed for possible future applications of this device. This, in turn, will result in time\\nand cost savings compared to the current coring method for properties determination.\\n\\n2. Study into the in-situ measurement of permeability of top sand layer:\\n\\nInitially, the project emphasis and focus were placed on the study of CB Wall\\'s properties and\\nthe QA/QC check of the Deep Cement Mixing (DCM) columns so that we can effectively support\\nthe on-site construction activities. As a result, the study on evaluating sand layer permeability\\nusing a non-destructive in-situ method was deferred till the on-site activities had completed.\\nNevertheless, a non-destructive, in-situ testing method to determine the permeability of\\nsandy soil was developed in the NUS laboratory. However, to ensure a comprehensive\\nunderstanding of the sand layer’s permeability changes with time and environmental\\nconditions, and their impact on polder function, we would like to request an extension of the\\nproject timeline to conduct a more in-depth study on sand permeability issue.\\n\\nThe proposed revised schedule for the above-mentioned activities is shown below:\\n\\nResistivity Measurement Device\\n\\nIn-situ measurement of sand\\npermeability\\n\\nWe are also proposing to continue the current practice of having the quarterly progress\\nmeeting with you and your engineers into the extended period.\\n\\nB. Proposed Virement of Fund:\\n\\nIn conjunction with the extension of project duration, we would also like to propose the following\\nvirement of funds, without requesting for additional funding:\\n(i) to transfer $20,000.00 from the \"Overseas Travel\" category to the \"Equipment\"\\ncategory.\\n(ii) to transfer $25,000.00 from the \"Manpower\" category to the \" Equipment\"\\ncategory, and\\n(iii) to transfer $55,000.00 from the \"Manpower\" category to the \" Other Operating\\nExpense\" category,\\n\\nIt is required to increase the funding for Equipment and Other Operating Expenses (OOE)\\nbecause of the decision to implement revised, reduced-size in-situ resistivity measurement\\n\\n2\\n\\n\\nPage 3\\nCollege of Design and Engineering\\nDean’s Office\\n\\nNUS\\n\\nNational University\\nof Singapore\\n\\ndevices (RMD). While the initial installation of RMDs adhered to the allocated budget, the\\nconsultant\\'s suggestion for revised devices of smaller sizes requires funding to research,\\nfabricate, install, and monitor these updated versions within the CB wall panel. It is imperative\\nto ensure adequate financial support for crucial project components, such as the fabrication of\\nmore resistivity devices for installations, procure more dataloggers with sustainable solar panel\\nsystems for autonomous data collection, and conduct laboratory and field tests for the study\\nof in-situ measurement of permeability of top sand layer.\\n\\nThere has been an underutilization of funds under the category for Manpower (EoM) and\\nOverseas travel, as the recruitment of researchers materialized a bit later than originally\\nplanned, and the number of overseas conference trips were reduced due to COVID-19. Hence,\\nit is proposed to reallocate the funds in Manpower (EoM) and Overseas Travel to Equipment\\nand Other Operating Expenses (OOE). NUS has assessed that there are sufficient funds available\\nin the remaining budget for Manpower and for Overseas Travel in 2024 after the virement.\\n\\nThe budget, before and after this proposed virement, is summarized below.\\n\\nTotal Budgeted: $1,124,132.00\\nLeftover money: $710,040.90 as of 13‘ Dec 2023.\\n\\n. Manpower (EoM) $730,416.67 $459,620.19 - $80,000.00 | $650,416.67 $379,620.19\\n2. Equipment $47,000.00 $1,056.61 + $45,000.00 | $92,000.00 $46,056.61\\n3. Consumables\\n\\na. Other Operating $87,360.00 $1,983.11 + $55,000.00 | $142,360.00 $56,983.11\\nExpenses (OOE)\\nb. Overseas Travel $72,000.00 $60,025.66 - $20,000.00 | $52,000.00 $40,025.66\\n4. Others (i.e. NUS $187,355.33 $187,355.33 - - $187,355.33\\nIndirect Costs)\\nTotal | $1,124,132.00 $710,040.90 - $1,124,132.00 | $710,040.90\\n\\nShould you require any additional information or have any queries regarding this proposal,\\nplease do not hesitate to contact me at ceecsh@nus.edu.sg . Thank you for your time and\\nconsideration.\\n\\nYours sincerely,\\n\\nCh\\n\\n——\\nDr CHEW Soon Hoe\\n\\nAsst Professor\\n\\nDepartment of Civil and Environmental Engineering\\nNational University of Singapore\\n\\nPI for JSA (Polder) project.\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_from_scanned_pdf(file_path: str):\n",
    "    \"\"\"Extracts text from a scanned PDF using OCR.\"\"\"\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    # Convert PDF pages to images\n",
    "    images = convert_from_path(file_path, poppler_path=\"/opt/homebrew/bin\")  # Adjust poppler_path if needed\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        extracted_text += f\"\\nPage {i+1}\\n{text.strip()}\\n\\n\"\n",
    "        print(f\"✅ Extracted OCR Text from Page {i+1}:\\n{text}\")\n",
    "\n",
    "    return extracted_text\n",
    "\n",
    "# Run OCR\n",
    "extract_text_from_scanned_pdf(\"/Users/lishuyao/Documents/NUS/MODS/Y3S2/Capstone/ODPRT-chatbot/processed_docs/emails_with_attachments/Agreement Type 01-01/processed_attachments/Extension and  Virement Request for JSA Polder project_NUS_processed_processed.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2 pages with images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def extract_useful_images_from_pdf(file_path: str, min_contour_area=10_000):\n",
    "    \"\"\"\n",
    "    Extracts useful images from a PDF file, ignoring logos, headers, and small graphics.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "        min_contour_area (int): Minimum contour area to consider an object as a useful figure.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted figures per page.\n",
    "    \"\"\"\n",
    "    save_directory = os.path.join(os.getcwd(), \"extracted_images\")\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    poppler_path = \"/opt/homebrew/bin\"  # Adjust if needed\n",
    "    images = convert_from_path(file_path, poppler_path=poppler_path)\n",
    "    extracted_figures = {}\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        try:\n",
    "            if image is None:\n",
    "                print(f\"Skipping Page {page_num+1} in {file_path} (No image content).\")\n",
    "                continue  # Skip empty pages\n",
    "\n",
    "            # Convert PIL image to NumPy array (ensure RGB format)\n",
    "            open_cv_image = np.array(image.convert(\"RGB\"))\n",
    "\n",
    "            if open_cv_image is None or open_cv_image.size == 0:\n",
    "                print(f\"Skipping Page {page_num+1} in {file_path} (Invalid image data).\")\n",
    "                continue  # Skip invalid images\n",
    "\n",
    "            # Convert to grayscale for better processing\n",
    "            gray = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Apply GaussianBlur to reduce noise\n",
    "            blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "            # Apply adaptive thresholding for better edge detection\n",
    "            thresh = cv2.adaptiveThreshold(\n",
    "                blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "            )\n",
    "\n",
    "            # Detect edges using Canny\n",
    "            edges = cv2.Canny(thresh, 50, 150)\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            figure_paths = []\n",
    "            figure_count = 0\n",
    "\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # **🚀 Filtering Step: Ignore small, thin, or too wide/tall images**\n",
    "                aspect_ratio = w / float(h)  # Width/Height Ratio\n",
    "                area = cv2.contourArea(contour)\n",
    "\n",
    "                if area < min_contour_area:\n",
    "                    continue  # Skip small objects\n",
    "\n",
    "                if aspect_ratio > 4 or aspect_ratio < 0.2:\n",
    "                    continue  # Skip banners, headers, and sidebars\n",
    "\n",
    "                # Extract the figure\n",
    "                figure_image = image.crop((x, y, x + w, y + h))\n",
    "\n",
    "                # Save the image\n",
    "                figure_path = os.path.join(save_directory, f\"page_{page_num+1}_figure_{figure_count+1}.png\")\n",
    "                figure_image.save(figure_path, \"PNG\")\n",
    "                figure_paths.append(figure_path)\n",
    "\n",
    "                figure_count += 1\n",
    "\n",
    "            if figure_paths:\n",
    "                extracted_figures[f\"Page {page_num+1}\"] = figure_paths\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing Page {page_num+1} of {file_path}: {e}\")\n",
    "\n",
    "    return extracted_figures\n",
    "\n",
    "# **Example Usage**\n",
    "pdf_path = \"/Users/lishuyao/Documents/NUS/MODS/Y3S2/Capstone/ODPRT-chatbot/processed_docs/emails_with_attachments/Agreement Type 01-01/processed_attachments/Extension and  Virement Request for JSA Polder project_NUS_processed_processed.pdf\"\n",
    "extracted_images = extract_useful_images_from_pdf(pdf_path)\n",
    "print(f\"Extracted {len(extracted_images)} pages with images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 2 pages with useful images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def extract_meaningful_images_from_pdf(file_path: str, min_contour_area=15_000):\n",
    "    \"\"\"\n",
    "    Extracts useful images from a PDF file, filtering out logos, headers, and small graphics.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "        min_contour_area (int): Minimum contour area to consider an object as useful.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted figures per page.\n",
    "    \"\"\"\n",
    "    save_directory = os.path.join(os.getcwd(), \"filtered_extracted_images\")\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    poppler_path = \"/opt/homebrew/bin\"  # Adjust if needed\n",
    "    images = convert_from_path(file_path, poppler_path=poppler_path, dpi=300)\n",
    "    extracted_figures = {}\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        try:\n",
    "            if image is None:\n",
    "                print(f\"Skipping Page {page_num+1} in {file_path} (No image content).\")\n",
    "                continue\n",
    "\n",
    "            # Convert PIL image to NumPy array (RGB)\n",
    "            open_cv_image = np.array(image.convert(\"RGB\"))\n",
    "\n",
    "            if open_cv_image is None or open_cv_image.size == 0:\n",
    "                print(f\"Skipping Page {page_num+1} in {file_path} (Invalid image data).\")\n",
    "                continue  # Skip invalid images\n",
    "\n",
    "            # Convert to grayscale and blur for noise reduction\n",
    "            gray = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2GRAY)\n",
    "            blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "            # Adaptive thresholding to enhance edges\n",
    "            thresh = cv2.adaptiveThreshold(\n",
    "                blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "            )\n",
    "\n",
    "            # Edge detection with Canny\n",
    "            edges = cv2.Canny(thresh, 50, 150)\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            figure_paths = []\n",
    "            figure_count = 0\n",
    "\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # 🚀 **Filtering Step: Ignore unwanted shapes**\n",
    "                aspect_ratio = w / float(h)\n",
    "                area = cv2.contourArea(contour)\n",
    "\n",
    "                if area < min_contour_area:\n",
    "                    continue  # Ignore small objects\n",
    "\n",
    "                if aspect_ratio > 4 or aspect_ratio < 0.25:\n",
    "                    continue  # Ignore banners, sidebars, and overly narrow/wide objects\n",
    "\n",
    "                # Convert to color space to check for monochrome images (logos, watermarks)\n",
    "                roi = open_cv_image[y:y + h, x:x + w]\n",
    "                mean_color = np.mean(roi, axis=(0, 1))  # Average color value\n",
    "\n",
    "                # If an image has very low color variance, it's likely a watermark/logo → Ignore it\n",
    "                if np.std(mean_color) < 15:\n",
    "                    continue\n",
    "\n",
    "                # Extract the figure\n",
    "                figure_image = image.crop((x, y, x + w, y + h))\n",
    "\n",
    "                # Save the image\n",
    "                figure_path = os.path.join(save_directory, f\"page_{page_num+1}_figure_{figure_count+1}.png\")\n",
    "                figure_image.save(figure_path, \"PNG\")\n",
    "                figure_paths.append(figure_path)\n",
    "\n",
    "                figure_count += 1\n",
    "\n",
    "            if figure_paths:\n",
    "                extracted_figures[f\"Page {page_num+1}\"] = figure_paths\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing Page {page_num+1} of {file_path}: {e}\")\n",
    "\n",
    "    return extracted_figures\n",
    "\n",
    "# **Example Usage**\n",
    "pdf_path = \"/Users/lishuyao/Documents/NUS/MODS/Y3S2/Capstone/ODPRT-chatbot/processed_docs/emails_with_attachments/Agreement Type 01-01/processed_attachments/Extension and  Virement Request for JSA Polder project_NUS_processed_processed.pdf\"\n",
    "extracted_images = extract_meaningful_images_from_pdf(pdf_path)\n",
    "print(f\"✅ Extracted {len(extracted_images)} pages with useful images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 3 pages with useful images and tables.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"USE THIS METHOD\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def extract_tables_and_figures_from_pdf(file_path: str, min_contour_area=10_000):\n",
    "    \"\"\"\n",
    "    Extracts meaningful images and tables from a PDF file, treating tables as full images.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "        min_contour_area (int): Minimum contour area to consider an object useful.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted figures and tables per page.\n",
    "    \"\"\"\n",
    "    save_directory = os.path.join(os.getcwd(), \"extracted_images\")\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    poppler_path = \"/opt/homebrew/bin\"  # Adjust if needed\n",
    "    images = convert_from_path(file_path, poppler_path=poppler_path, dpi=300)\n",
    "    extracted_elements = {}\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        try:\n",
    "            if image is None:\n",
    "                print(f\"Skipping Page {page_num+1} in {file_path} (No image content).\")\n",
    "                continue\n",
    "\n",
    "            # Convert PIL image to NumPy array (RGB)\n",
    "            open_cv_image = np.array(image.convert(\"RGB\"))\n",
    "\n",
    "            if open_cv_image is None or open_cv_image.size == 0:\n",
    "                print(f\"Skipping Page {page_num+1} in {file_path} (Invalid image data).\")\n",
    "                continue\n",
    "\n",
    "            # Convert to grayscale and apply Gaussian blur for noise reduction\n",
    "            gray = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2GRAY)\n",
    "            blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "            # Adaptive thresholding for better table & figure detection\n",
    "            thresh = cv2.adaptiveThreshold(\n",
    "                blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 4\n",
    "            )\n",
    "\n",
    "            # Detect horizontal and vertical lines (to detect tables)\n",
    "            kernel_horizontal = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 1))\n",
    "            kernel_vertical = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 25))\n",
    "\n",
    "            horizontal_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_horizontal)\n",
    "            vertical_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_vertical)\n",
    "\n",
    "            # Combine horizontal and vertical lines to detect full tables\n",
    "            table_mask = cv2.add(horizontal_lines, vertical_lines)\n",
    "\n",
    "            # Edge detection\n",
    "            edges = cv2.Canny(thresh, 50, 150)\n",
    "\n",
    "            # Find contours (for both tables and figures)\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            figure_paths = []\n",
    "            table_paths = []\n",
    "            figure_count, table_count = 0, 0\n",
    "\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                area = cv2.contourArea(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "\n",
    "                # 🚀 **Table Detection**: Looks for grid-like structures\n",
    "                if cv2.countNonZero(table_mask[y:y+h, x:x+w]) > 0.5 * area:\n",
    "                    if area < min_contour_area:\n",
    "                        continue  # Ignore small detected tables\n",
    "                    table_image = image.crop((x, y, x + w, y + h))\n",
    "                    table_path = os.path.join(save_directory, f\"page_{page_num+1}_table_{table_count+1}.png\")\n",
    "                    table_image.save(table_path, \"PNG\")\n",
    "                    table_paths.append(table_path)\n",
    "                    table_count += 1\n",
    "                    continue  # Skip further processing for tables\n",
    "\n",
    "                # 🚀 **Figure Detection**: Looks for large, meaningful images\n",
    "                if area > min_contour_area and 0.3 < aspect_ratio < 3:\n",
    "                    figure_image = image.crop((x, y, x + w, y + h))\n",
    "                    \n",
    "                    figure_path = os.path.join(save_directory, f\"page_{page_num+1}_figure_{figure_count+1}.png\")\n",
    "                    figure_image.save(figure_path, \"PNG\")\n",
    "                    figure_paths.append(figure_path)\n",
    "                    figure_count += 1\n",
    "\n",
    "            if figure_paths or table_paths:\n",
    "                extracted_elements[f\"Page {page_num+1}\"] = {\n",
    "                    \"figures\": figure_paths,\n",
    "                    \"tables\": table_paths\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing Page {page_num+1} of {file_path}: {e}\")\n",
    "\n",
    "    return extracted_elements\n",
    "\n",
    "# **Example Usage**\n",
    "extracted_data = extract_tables_and_figures_from_pdf(pdf_path)\n",
    "print(f\"✅ Extracted {len(extracted_data)} pages with useful images and tables.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 3 pages with useful images and tables.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def extract_tables_and_figures_from_pdf(file_path: str, min_contour_area=10_000, max_logo_area=50_000):\n",
    "    \"\"\"\n",
    "    Extracts tables and figures from a PDF, treating tables as whole images and avoiding logos.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "        min_contour_area (int): Minimum contour area to consider an object useful.\n",
    "        max_logo_area (int): Maximum area for logos and small non-useful images.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted tables and figures per page.\n",
    "    \"\"\"\n",
    "    save_directory = os.path.join(os.getcwd(), \"extracted_images\")\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    poppler_path = \"/opt/homebrew/bin\"  # Adjust if needed\n",
    "    images = convert_from_path(file_path, poppler_path=poppler_path, dpi=300)\n",
    "    extracted_elements = {}\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        try:\n",
    "            if image is None:\n",
    "                print(f\"Skipping Page {page_num+1} in {file_path} (No image content).\")\n",
    "                continue\n",
    "\n",
    "            # Convert PIL image to NumPy array (RGB)\n",
    "            open_cv_image = np.array(image.convert(\"RGB\"))\n",
    "\n",
    "            if open_cv_image is None or open_cv_image.size == 0:\n",
    "                print(f\"Skipping Page {page_num+1} in {file_path} (Invalid image data).\")\n",
    "                continue\n",
    "\n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Adaptive thresholding to enhance table structure\n",
    "            thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                           cv2.THRESH_BINARY_INV, 15, 4)\n",
    "\n",
    "            # Morphological operations to detect lines (tables)\n",
    "            kernel_horizontal = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
    "            kernel_vertical = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))\n",
    "            horizontal_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_horizontal)\n",
    "            vertical_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel_vertical)\n",
    "            table_mask = cv2.add(horizontal_lines, vertical_lines)\n",
    "\n",
    "            # Edge detection\n",
    "            edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "            # Find contours (tables and figures)\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            figure_paths = []\n",
    "            table_paths = []\n",
    "            figure_count, table_count = 0, 0\n",
    "\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                area = cv2.contourArea(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "\n",
    "                # **Skip small logos and noise**\n",
    "                if area < max_logo_area and aspect_ratio < 2 and y < 100:\n",
    "                    continue  # Likely a logo or header\n",
    "\n",
    "                # **Table Detection**: Uses structured grid-like features\n",
    "                if cv2.countNonZero(table_mask[y:y+h, x:x+w]) > 0.5 * area:\n",
    "                    if area < min_contour_area:\n",
    "                        continue  # Ignore small detected tables\n",
    "                    table_image = image.crop((x, y, x + w, y + h))\n",
    "                    table_path = os.path.join(save_directory, f\"page_{page_num+1}_table_{table_count+1}.png\")\n",
    "                    table_image.save(table_path, \"PNG\")\n",
    "                    table_paths.append(table_path)\n",
    "                    table_count += 1\n",
    "                    continue  # Skip further processing for tables\n",
    "\n",
    "                # **Figure Detection**: Captures meaningful large figures\n",
    "                if area > min_contour_area and 0.3 < aspect_ratio < 3:\n",
    "                    figure_image = image.crop((x, y, x + w, y + h))\n",
    "                    figure_path = os.path.join(save_directory, f\"page_{page_num+1}_figure_{figure_count+1}.png\")\n",
    "                    figure_image.save(figure_path, \"PNG\")\n",
    "                    figure_paths.append(figure_path)\n",
    "                    figure_count += 1\n",
    "\n",
    "            if figure_paths or table_paths:\n",
    "                extracted_elements[f\"Page {page_num+1}\"] = {\n",
    "                    \"figures\": figure_paths,\n",
    "                    \"tables\": table_paths\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing Page {page_num+1} of {file_path}: {e}\")\n",
    "\n",
    "    return extracted_elements\n",
    "\n",
    "# **Example Usage**\n",
    "extracted_data = extract_tables_and_figures_from_pdf(pdf_path)\n",
    "print(f\"✅ Extracted {len(extracted_data)} pages with useful images and tables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 1 pages with useful images and tables.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "def extract_tables_and_figures_from_pdf(file_path: str, min_table_area=20_000, min_figure_area=20_000, max_logo_area=60_000):\n",
    "    \"\"\"\n",
    "    Extracts tables and figures from a PDF while avoiding logos.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "        min_table_area (int): Minimum area for a table to be considered valid.\n",
    "        min_figure_area (int): Minimum area for a figure to be considered valid.\n",
    "        max_logo_area (int): Maximum area for logos (small decorations).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted tables and figures per page.\n",
    "    \"\"\"\n",
    "    save_directory = os.path.join(os.getcwd(), \"extracted_images\")\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    poppler_path = \"/opt/homebrew/bin\"  # Adjust if needed\n",
    "    images = convert_from_path(file_path, poppler_path=poppler_path, dpi=300)\n",
    "    extracted_elements = {}\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        try:\n",
    "            if image is None:\n",
    "                print(f\"Skipping Page {page_num+1} (No image content).\")\n",
    "                continue\n",
    "\n",
    "            # Convert PIL image to NumPy array (RGB)\n",
    "            open_cv_image = np.array(image.convert(\"RGB\"))\n",
    "\n",
    "            if open_cv_image is None or open_cv_image.size == 0:\n",
    "                print(f\"Skipping Page {page_num+1} (Invalid image data).\")\n",
    "                continue\n",
    "\n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # **Step 1: Table Detection**\n",
    "            # Apply adaptive thresholding to enhance table structure\n",
    "            thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                           cv2.THRESH_BINARY_INV, 15, 4)\n",
    "\n",
    "            # Use Hough Line Transform to detect grid structures (tables)\n",
    "            edges = cv2.Canny(thresh, 50, 150)\n",
    "            lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=100, maxLineGap=5)\n",
    "\n",
    "            table_mask = np.zeros_like(gray)\n",
    "            if lines is not None:\n",
    "                for line in lines:\n",
    "                    x1, y1, x2, y2 = line[0]\n",
    "                    cv2.line(table_mask, (x1, y1), (x2, y2), 255, 2)  # Draw detected table lines\n",
    "\n",
    "            # **Step 2: Contour Detection (Tables & Figures)**\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            figure_paths = []\n",
    "            table_paths = []\n",
    "            figure_count, table_count = 0, 0\n",
    "\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                area = cv2.contourArea(contour)\n",
    "                aspect_ratio = w / float(h)\n",
    "\n",
    "                # **Ignore logos & small decorative elements**\n",
    "                if area < max_logo_area and y < 100:\n",
    "                    continue  # Likely a logo/header\n",
    "\n",
    "                # **Table Detection: Uses structured grid-like features**\n",
    "                if cv2.countNonZero(table_mask[y:y+h, x:x+w]) > 0.4 * area:\n",
    "                    if area < min_table_area:\n",
    "                        continue  # Ignore small detected tables\n",
    "                    table_image = image.crop((x, y, x + w, y + h))\n",
    "                    table_path = os.path.join(save_directory, f\"page_{page_num+1}_table_{table_count+1}.png\")\n",
    "                    table_image.save(table_path, \"PNG\")\n",
    "                    table_paths.append(table_path)\n",
    "                    table_count += 1\n",
    "                    continue  # Skip further processing for tables\n",
    "\n",
    "                # **Figure Detection: Captures meaningful figures**\n",
    "                if area > min_figure_area and 0.3 < aspect_ratio < 3:\n",
    "                    figure_image = image.crop((x, y, x + w, y + h))\n",
    "                    figure_path = os.path.join(save_directory, f\"page_{page_num+1}_figure_{figure_count+1}.png\")\n",
    "                    figure_image.save(figure_path, \"PNG\")\n",
    "                    figure_paths.append(figure_path)\n",
    "                    figure_count += 1\n",
    "\n",
    "            if figure_paths or table_paths:\n",
    "                extracted_elements[f\"Page {page_num+1}\"] = {\n",
    "                    \"figures\": figure_paths,\n",
    "                    \"tables\": table_paths\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing Page {page_num+1}: {e}\")\n",
    "\n",
    "    return extracted_elements\n",
    "\n",
    "# **Example Usage**\n",
    "extracted_data = extract_tables_and_figures_from_pdf(pdf_path)\n",
    "print(f\"✅ Extracted {len(extracted_data)} pages with useful images and tables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PageImage' object has no attribute 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extracted_elements\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# **Example Usage**\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m \u001b[43mextract_tables_and_figures_pdfimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Extracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(extracted_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pages with useful images and tables.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 37\u001b[0m, in \u001b[0;36mextract_tables_and_figures_pdfimage\u001b[0;34m(file_path, min_figure_area, max_logo_area)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Likely a logo/header\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# **Convert `PageImage` to a PIL Image**\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m image_obj \u001b[38;5;241m=\u001b[39m \u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m  \u001b[38;5;66;03m# Extracts PIL image\u001b[39;00m\n\u001b[1;32m     38\u001b[0m cropped_img \u001b[38;5;241m=\u001b[39m image_obj\u001b[38;5;241m.\u001b[39mcrop((x, y, x \u001b[38;5;241m+\u001b[39m w, y \u001b[38;5;241m+\u001b[39m h))  \u001b[38;5;66;03m# Crop to bounding box\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# **Save the extracted image**\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PageImage' object has no attribute 'image'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from PIL import Image\n",
    "\n",
    "def extract_tables_and_figures_pdfimage(file_path: str, min_figure_area=20_000, max_logo_area=60_000):\n",
    "    \"\"\"\n",
    "    Extracts tables and figures as embedded images from a PDF while avoiding logos.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the PDF file.\n",
    "        min_figure_area (int): Minimum area for a figure to be considered valid.\n",
    "        max_logo_area (int): Maximum area for logos (small decorations).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing extracted tables and figures per page.\n",
    "    \"\"\"\n",
    "    save_directory = os.path.join(os.getcwd(), \"extracted_images\")\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    extracted_elements = {}\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            figures = []\n",
    "            tables = []\n",
    "            \n",
    "            # Extract all images embedded in the PDF\n",
    "            for img_index, img in enumerate(page.images):\n",
    "                x, y, w, h = img[\"x0\"], img[\"top\"], img[\"x1\"] - img[\"x0\"], img[\"bottom\"] - img[\"top\"]\n",
    "                area = w * h\n",
    "\n",
    "                # **Ignore logos & small decorative elements**\n",
    "                if area < max_logo_area and y < 100:\n",
    "                    continue  # Likely a logo/header\n",
    "\n",
    "                # **Convert `PageImage` to a PIL Image**\n",
    "                image_obj = page.to_image().image  # Extracts PIL image\n",
    "                cropped_img = image_obj.crop((x, y, x + w, y + h))  # Crop to bounding box\n",
    "\n",
    "                # **Save the extracted image**\n",
    "                image_path = os.path.join(save_directory, f\"page_{page_num+1}_img_{img_index+1}.png\")\n",
    "                cropped_img.save(image_path, \"PNG\")\n",
    "\n",
    "                # **Classify as figure or table**\n",
    "                if area > min_figure_area:\n",
    "                    figures.append(image_path)\n",
    "                else:\n",
    "                    tables.append(image_path)\n",
    "\n",
    "            # Store extracted tables and figures\n",
    "            if figures or tables:\n",
    "                extracted_elements[f\"Page {page_num+1}\"] = {\"figures\": figures, \"tables\": tables}\n",
    "\n",
    "    return extracted_elements\n",
    "\n",
    "# **Example Usage**\n",
    "extracted_data = extract_tables_and_figures_pdfimage(pdf_path)\n",
    "print(f\"✅ Extracted {len(extracted_data)} pages with useful images and tables.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odprt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
